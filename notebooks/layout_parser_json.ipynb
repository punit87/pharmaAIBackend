{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "rm -rf /root/.torch/iopath_cache/\n"
      ],
      "metadata": {
        "id": "-YTO0yQP39Ra"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir -p /root/.torch/iopath_cache/s/57zjbwv6gh3srry/"
      ],
      "metadata": {
        "id": "eL0wDwTo6o9o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "ZTVAngaX2j8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Dependency Explanations:\n",
        "\n",
        "sys:            Provides access to Python interpreter variables and functions, used here\n",
        "                to check Python version\n",
        "\n",
        "libreoffice:    Office suite used to convert DOCX files to PDF format for processing\n",
        "\n",
        "poppler-utils:  PDF rendering library that powers the pdf2image package for PDF to\n",
        "                image conversion\n",
        "\n",
        "tesseract-ocr:  Open-source OCR engine that extracts text from images\n",
        "\n",
        "torch:          PyTorch deep learning framework that provides tensor computation and\n",
        "                neural networks\n",
        "\n",
        "torchvision:    Computer vision library that works with PyTorch for image processing tasks\n",
        "\n",
        "pdf2image:      Converts PDF documents to images using poppler under the hood\n",
        "\n",
        "opencv-python:  Computer vision library for image processing operations\n",
        "\n",
        "layoutparser:   Library for document layout analysis and segmentation\n",
        "\n",
        "pytesseract:    Python wrapper for Google's Tesseract OCR engine\n",
        "\n",
        "cython:         Language that makes writing C extensions for Python easier, required\n",
        "                for detectron2\n",
        "\n",
        "pycocotools:    Tools for working with the COCO dataset format, used by detectron2\n",
        "\n",
        "fvcore:         Core libraries for computer vision research, used by detectron2\n",
        "\n",
        "detectron2:     Facebook AI Research's object detection and segmentation framework\n",
        "                used by layoutparser\n",
        "'''\n",
        "\n",
        "\n",
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y libreoffice poppler-utils tesseract-ocr -qq  # For DOCX to PDF, pdf2image, and OCR\n",
        "\n",
        "# Clean up existing torch-related packages to avoid conflicts\n",
        "#!pip uninstall torch torchaudio torchvision fastai layoutparser detectron2 fvcore -y --quiet\n",
        "\n",
        "# Install latest Python dependencies\n",
        "!pip install torch torchvision pdf2image opencv-python layoutparser pytesseract --quiet\n",
        "\n",
        "# Install prerequisites for detectron2\n",
        "!pip install cython pycocotools fvcore --quiet\n",
        "\n",
        "# Install detectron2 from source (compatible with torch 2.6.0+cu124)\n",
        "#!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "!pip install python-docx\n",
        "!pip install --upgrade pillow\n",
        "!sudo apt-get install tesseract-ocr-eng\n",
        "#!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.5#egg=detectron2\"\n",
        "!pip install -U 'git+https://github.com/facebookresearch/detectron2.git@ff53992b1985b63bd3262b5a36167098e3dada02'\n",
        "!pip install \"layoutparser[ocr]\"\n",
        "\n",
        "!pip install sentence-transformers faiss-cpu fastapi uvicorn pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJP6if5NBgFW",
        "outputId": "6228de2c-25ae-4b93-e632-47d569242775"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git@ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision ff53992b1985b63bd3262b5a36167098e3dada02) to /tmp/pip-req-build-ew6a2yiy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-ew6a2yiy\n",
            "  Running command git rev-parse -q --verify 'sha^ff53992b1985b63bd3262b5a36167098e3dada02'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Running command git checkout -q ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: layoutparser[ocr] in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (6.0.2)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.1.9)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.11.5)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.17.0)\n",
            "Requirement already satisfied: google-cloud-vision==1 in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.0.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.3.13)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.34.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->layoutparser[ocr]) (4.67.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->layoutparser[ocr]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2025.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber->layoutparser[ocr]) (20231228)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber->layoutparser[ocr]) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract->layoutparser[ocr]) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.69.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.48.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->layoutparser[ocr]) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (4.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (0.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, faiss-cpu, starlette, fastapi\n",
            "Successfully installed faiss-cpu-1.10.0 fastapi-0.115.11 pyngrok-7.2.3 starlette-0.46.1 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /root/.torch/iopath_cache/s/57zjbwv6gh3srry/model_final.pth?dl=1 /root/.torch/iopath_cache/s/57zjbwv6gh3srry/model_final.pth"
      ],
      "metadata": {
        "id": "RiLbMUFwagTQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Model, Convert word->pdf->png, extract and classify content, store metadata and index"
      ],
      "metadata": {
        "id": "nQcCogrr2qy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "\n",
        "import layoutparser as lp\n",
        "print(f\"LayoutParser version: {lp.__version__}\")\n",
        "\n",
        "import detectron2\n",
        "print(f\"Detectron2 version: {detectron2.__version__}\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from docx import Document\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "from docx.shared import Pt\n",
        "import re\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive,userdata\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# Import new libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# Set up directories\n",
        "SOURCE_DIR = \"/content/drive/My Drive/lifesciences/training_documents\"\n",
        "PDF_STAGING_DIR = \"/content/drive/My Drive/lifesciences/staging/pdf\"\n",
        "IMG_STAGING_DIR = \"/content/drive/My Drive/lifesciences/staging/images\"\n",
        "METADATA_FILE = \"/content/drive/My Drive/lifesciences/metadata.json\"\n",
        "ANNOTATED_DIR = \"/content/drive/My Drive/lifesciences/staging/annotated\"\n",
        "FAISS_INDEX_PATH = \"/content/drive/My Drive/lifesciences/faiss_index.index\"\n",
        "\n",
        "os.makedirs(SOURCE_DIR, exist_ok=True)\n",
        "os.makedirs(PDF_STAGING_DIR, exist_ok=True)\n",
        "os.makedirs(IMG_STAGING_DIR, exist_ok=True)\n",
        "os.makedirs(ANNOTATED_DIR, exist_ok=True)\n",
        "\n",
        "# Increase PIL's image size limit\n",
        "Image.MAX_IMAGE_PIXELS = 100000000\n",
        "\n",
        "# Initialize ID sequence\n",
        "id_seq = 1\n",
        "\n",
        "# Initialize SentenceTransformer\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Loaded SentenceTransformer: all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize FAISS index\n",
        "dimension = 384  # all-MiniLM-L6-v2 output dimension\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "metadata_entries = []  # To store JSON entries for mapping\n",
        "\n",
        "# Load PubLayNet model\n",
        "MODEL_CONFIG = \"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\"\n",
        "model = lp.Detectron2LayoutModel(config_path=MODEL_CONFIG,\n",
        "                                model_path='/root/.torch/iopath_cache/s/57zjbwv6gh3srry/model_final.pth',\n",
        "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.2],\n",
        "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"})\n",
        "\n",
        "print(\"Loading PubLayNet model...\")\n",
        "\n",
        "# Initialize Tesseract OCR\n",
        "ocr_agent = lp.TesseractAgent(languages='eng', config='--psm 6 --oem 1')\n",
        "\n",
        "# Color map for visualization (BGR format for OpenCV)\n",
        "COLORS = {\n",
        "    \"title\": (255, 0, 0),    # Blue\n",
        "    \"text\": (0, 255, 0),     # Green\n",
        "    \"list\": (0, 0, 255),     # Red\n",
        "    \"table\": (255, 255, 0),  # Cyan\n",
        "    \"figure\": (255, 0, 255), # Magenta\n",
        "}\n",
        "\n",
        "def add_table_border(table):\n",
        "    \"\"\"Add thick borders to a table, including internal gridlines.\"\"\"\n",
        "    tbl = table._tbl\n",
        "    tblBorders = OxmlElement('w:tblBorders')\n",
        "    for border_name in ['top', 'left', 'bottom', 'right', 'insideH', 'insideV']:\n",
        "        border = OxmlElement(f'w:{border_name}')\n",
        "        border.set(qn('w:val'), 'single')\n",
        "        border.set(qn('w:sz'), '12')\n",
        "        border.set(qn('w:color'), '000000')\n",
        "        tblBorders.append(border)\n",
        "    tbl.append(tblBorders)\n",
        "    for row in table.rows:\n",
        "        for cell in row.cells:\n",
        "            tc = cell._tc\n",
        "            tcBorders = OxmlElement('w:tcBorders')\n",
        "            for border_name in ['top', 'left', 'bottom', 'right']:\n",
        "                border = OxmlElement(f'w:{border_name}')\n",
        "                border.set(qn('w:val'), 'single')\n",
        "                border.set(qn('w:sz'), '8')\n",
        "                border.set(qn('w:color'), '000000')\n",
        "                tcBorders.append(border)\n",
        "            tc.append(tcBorders)\n",
        "\n",
        "def adjust_docx_titles_and_spacing(docx_path, temp_docx_path, min_spacing=40):\n",
        "    \"\"\"Detect titles, convert them to all caps, and adjust spacing.\"\"\"\n",
        "    doc = Document(docx_path)\n",
        "    for para in doc.paragraphs:\n",
        "        is_title = False\n",
        "        if para.style and \"Heading\" in para.style.name:\n",
        "            is_title = True\n",
        "        elif para.runs and all(run.bold for run in para.runs if run.text.strip()):\n",
        "            is_title = True\n",
        "        if is_title and para.text.strip():\n",
        "            original_text = para.text\n",
        "            para.clear()\n",
        "            new_run = para.add_run(original_text.upper())\n",
        "            new_run.bold = True\n",
        "            new_run.underline = True\n",
        "            print(f\"Formatted title: '{original_text}' → '{new_run.text}'\")\n",
        "    for table in doc.tables:\n",
        "        add_table_border(table)\n",
        "    doc.save(temp_docx_path)\n",
        "    return temp_docx_path\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, output_dir):\n",
        "    \"\"\"Convert DOCX to PDF using LibreOffice with enforced vertical gaps.\"\"\"\n",
        "    if not os.path.exists(docx_path):\n",
        "        raise FileNotFoundError(f\"Source DOCX file not found: {docx_path}\")\n",
        "    final_output_path = os.path.join(output_dir, f\"{Path(docx_path).stem}.pdf\")\n",
        "    temp_docx_path = os.path.join(output_dir, f\"{Path(docx_path).stem}_temp.docx\")\n",
        "    adjusted_docx = adjust_docx_titles_and_spacing(docx_path, temp_docx_path, min_spacing=40)\n",
        "    print(f\"Converting {adjusted_docx} to {final_output_path}...\")\n",
        "    result = subprocess.run([\n",
        "        'libreoffice',\n",
        "        '--headless',\n",
        "        '--convert-to',\n",
        "        'pdf',\n",
        "        adjusted_docx,\n",
        "        '--outdir',\n",
        "        output_dir\n",
        "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if result.returncode != 0:\n",
        "        raise subprocess.CalledProcessError(\n",
        "            result.returncode,\n",
        "            result.args,\n",
        "            output=result.stdout,\n",
        "            stderr=result.stderr\n",
        "        )\n",
        "    print(f\"LibreOffice stdout: {result.stdout}\")\n",
        "    if result.stderr:\n",
        "        print(f\"LibreOffice stderr: {result.stderr}\")\n",
        "    temp_pdf_path = os.path.join(output_dir, f\"{Path(adjusted_docx).stem}.pdf\")\n",
        "    if os.path.exists(temp_pdf_path):\n",
        "        os.rename(temp_pdf_path, final_output_path)\n",
        "        print(f\"Renamed {temp_pdf_path} to {final_output_path}\")\n",
        "    if not os.path.exists(final_output_path):\n",
        "        raise FileNotFoundError(f\"Final PDF file was not created: {final_output_path}\")\n",
        "    if os.path.exists(temp_docx_path):\n",
        "        os.remove(temp_docx_path)\n",
        "    return final_output_path\n",
        "\n",
        "def convert_pdf_to_png(pdf_path, output_dir):\n",
        "    \"\"\"Convert PDF pages to PNG images.\"\"\"\n",
        "    pdf_name = Path(pdf_path).stem\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path, dpi=1000)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to convert PDF to images: {str(e)}\")\n",
        "        return []\n",
        "    if not images:\n",
        "        print(f\"No images generated from {pdf_path}\")\n",
        "        return []\n",
        "    image_paths = []\n",
        "    for i, image in enumerate(images):\n",
        "        img_array = np.array(image)\n",
        "        if img_array.size == 0:\n",
        "            print(f\"Image {i+1} is empty for {pdf_name}\")\n",
        "            continue\n",
        "        output_path = os.path.join(output_dir, f\"{pdf_name}_page_{i + 1}.png\")\n",
        "        image.save(output_path, \"PNG\", quality=95)\n",
        "        image_paths.append(output_path)\n",
        "        print(f\"Saved image: {output_path}\")\n",
        "    return image_paths\n",
        "\n",
        "def is_overlapping(rect1, rect2):\n",
        "    \"\"\"Check if two rectangles overlap.\"\"\"\n",
        "    x1, y1, x2, y2 = rect1\n",
        "    x3, y3, x4, y4 = rect2\n",
        "    if x2 <= x3 or x4 <= x1 or y2 <= y3 or y4 <= y1:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def process_layout(image_path):\n",
        "    \"\"\"Process PNG using LayoutParser and extract elements with visualization, skipping overlapping text.\"\"\"\n",
        "    global id_seq\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
        "    annotated_image = image.copy()\n",
        "    layout = model.detect(image)\n",
        "    sorted_layout = sorted(layout, key=lambda x: x.coordinates[1])\n",
        "    results = []\n",
        "    current_section = \"No Title\"\n",
        "    structural_regions = []\n",
        "    for block in sorted_layout:\n",
        "        block_type = block.type.lower()\n",
        "        if block_type in [\"table\", \"list\", \"title\"]:\n",
        "            structural_regions.append({\n",
        "                \"type\": block_type,\n",
        "                \"coordinates\": list(map(int, block.coordinates))\n",
        "            })\n",
        "    for block in sorted_layout:\n",
        "        x1, y1, x2, y2 = map(int, block.coordinates)\n",
        "        block_type = block.type.lower()\n",
        "        print(f\"Detected Type: {block_type}, Coordinates: ({x1}, {y1}, {x2}, {y2})\")\n",
        "        if block_type == \"text\":\n",
        "            text_coords = (x1, y1, x2, y2)\n",
        "            overlaps = False\n",
        "            for region in structural_regions:\n",
        "                region_coords = region[\"coordinates\"]\n",
        "                if is_overlapping(text_coords, region_coords):\n",
        "                    overlaps = True\n",
        "                    print(f\"Skipping overlapping text at ({x1}, {y1}, {x2}, {y2}) with {region['type']}\")\n",
        "                    break\n",
        "            if overlaps:\n",
        "                continue\n",
        "        if block_type in [\"list\", \"table\"]:\n",
        "            cropped_image = image[y1:y2, x1:x2]\n",
        "            content = ocr_agent.detect(cropped_image) or \"\"\n",
        "            if block_type == \"list\":\n",
        "                lines = content.split('\\n')\n",
        "                cleaned_lines = [re.sub(r'[^a-zA-Z0-9\\s]', '', line.strip()) for line in lines if line.strip()]\n",
        "                content = '\\n'.join(cleaned_lines) if cleaned_lines else \"\"\n",
        "            elif block_type == \"table\":\n",
        "                rows = content.split('\\n')\n",
        "                cleaned_rows = []\n",
        "                for row in rows:\n",
        "                    if row.strip():\n",
        "                        columns = row.split()\n",
        "                        cleaned_row = '-'.join(col.strip() for col in columns if col.strip())\n",
        "                        cleaned_rows.append(cleaned_row.replace('\\n', ' '))\n",
        "                content = '\\n'.join(cleaned_rows) if cleaned_rows else \"Table Content\"\n",
        "        else:\n",
        "            cropped_image = image[y1:y2, x1:x2]\n",
        "            if block_type == \"title\":\n",
        "                content = ocr_agent.detect(cropped_image) or \"Untitled\"\n",
        "                current_section = content.lower()\n",
        "            else:\n",
        "                content = ocr_agent.detect(cropped_image) or \"\"\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), COLORS[block_type], 2)\n",
        "        cv2.putText(annotated_image, block_type, (x1, y1-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLORS[block_type], 2)\n",
        "        result = {\n",
        "            \"id\": id_seq,\n",
        "            \"urs\": Path(image_path).stem,\n",
        "            \"section\": current_section,\n",
        "            \"type\": block_type,\n",
        "            \"content\": content.strip(),\n",
        "            \"coordinates\": list(block.coordinates),\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"source_file\": image_path\n",
        "        }\n",
        "        results.append(result)\n",
        "        id_seq += 1\n",
        "    annotated_path = os.path.join(ANNOTATED_DIR, Path(image_path).name.replace(\".png\", \"_annotated.png\"))\n",
        "    cv2.imwrite(annotated_path, annotated_image)\n",
        "    print(f\"Saved annotated image: {annotated_path}\")\n",
        "    append_to_metadata(results)\n",
        "    return results\n",
        "\n",
        "def append_to_metadata(data):\n",
        "    \"\"\"Append results to metadata.json\"\"\"\n",
        "    if not os.path.exists(METADATA_FILE):\n",
        "        with open(METADATA_FILE, 'w') as f:\n",
        "            json.dump([], f)\n",
        "    with open(METADATA_FILE, 'r') as f:\n",
        "        existing_data = json.load(f)\n",
        "    existing_data.extend(data)\n",
        "    with open(METADATA_FILE, 'w') as f:\n",
        "        json.dump(existing_data, f, indent=2)\n",
        "\n",
        "def process_file(file_path):\n",
        "    \"\"\"Process a single file through all steps\"\"\"\n",
        "    file_ext = Path(file_path).suffix.lower()\n",
        "    pdf_path = file_path\n",
        "    if file_ext == '.docx':\n",
        "        try:\n",
        "            pdf_path = convert_docx_to_pdf(file_path, PDF_STAGING_DIR)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting DOCX to PDF for {file_path}: {str(e)}\")\n",
        "            return\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"PDF file not found: {pdf_path}. Skipping...\")\n",
        "        return\n",
        "    try:\n",
        "        png_paths = convert_pdf_to_png(pdf_path, IMG_STAGING_DIR)\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting PDF to PNG for {pdf_path}: {str(e)}\")\n",
        "        return\n",
        "    all_results = []\n",
        "    for png_path in png_paths:\n",
        "        try:\n",
        "            results = process_layout(png_path)\n",
        "            all_results.extend(results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing layout for {png_path}: {str(e)}\")\n",
        "    append_to_metadata(all_results)\n",
        "    print(f\"Processed: {Path(file_path).name}, Added {len(all_results)} entries\")\n",
        "    return all_results\n",
        "\n",
        "def build_faiss_index():\n",
        "    \"\"\"Build FAISS index from metadata.json with URS and section indexing\"\"\"\n",
        "    global faiss_index, metadata_entries\n",
        "\n",
        "    if not os.path.exists(METADATA_FILE):\n",
        "        print(f\"Metadata file {METADATA_FILE} not found. Run processing first.\")\n",
        "        return\n",
        "\n",
        "    with open(METADATA_FILE, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    if not metadata:\n",
        "        print(\"No entries in metadata to index.\")\n",
        "        return\n",
        "\n",
        "    # Prepare data for FAISS indexing\n",
        "    combined_texts = []\n",
        "    metadata_entries = []\n",
        "\n",
        "    for entry in metadata:\n",
        "        urs = entry.get(\"urs\", \"\").strip()\n",
        "        section = entry.get(\"section\", \"\").strip()\n",
        "        content = entry.get(\"content\", \"\").strip()\n",
        "        content_type = entry.get(\"type\", \"\").strip()\n",
        "        if content:\n",
        "            # Create a combined text for better indexing\n",
        "            combined_text = f\"{content_type} {urs} {section} {content} \"\n",
        "            combined_texts.append(combined_text)\n",
        "            print(f\"Combined Text: {combined_text}\")\n",
        "\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = sentence_model.encode(combined_texts, convert_to_numpy=True)\n",
        "    print(f\"Generated embeddings for {len(combined_texts)} entries\")\n",
        "    # Reinitialize FAISS index\n",
        "    dimension = embeddings.shape[1]\n",
        "    print(f\"Dimension of embeddings: {dimension}\")\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)\n",
        "    faiss_index.add(embeddings)\n",
        "\n",
        "    # Save index\n",
        "    faiss.write_index(faiss_index, FAISS_INDEX_PATH)\n",
        "    print(f\"FAISS index built with {len(combined_texts)} entries and saved to {FAISS_INDEX_PATH}\")\n",
        "\n",
        "\n",
        "def process_and_index():\n",
        "    \"\"\"Process files and build FAISS index\"\"\"\n",
        "    for filename in sorted(os.listdir(SOURCE_DIR)):\n",
        "        file_path = os.path.join(SOURCE_DIR, filename)\n",
        "        if os.path.isfile(file_path) and filename.lower().endswith(('.docx', '.pdf')):\n",
        "            print(f\"Starting: {filename}\")\n",
        "            process_file(file_path)\n",
        "    print(f\"Processing complete. Total entries: {id_seq - 1}\")\n",
        "    build_faiss_index()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    !nvidia-smi | grep \"CUDA Version\" || echo \"nvidia-smi not found\"\n",
        "    print(\"Processing files from:\", SOURCE_DIR)\n",
        "    process_and_index()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iet4GTIOJpI2",
        "outputId": "a005e20a-7dfc-446d-e8b9-87908624aa37"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.5.1+cu124\n",
            "Torchvision version: 0.20.1+cu124\n",
            "LayoutParser version: 0.3.4\n",
            "Detectron2 version: 0.6\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading PubLayNet model...\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "nvidia-smi not found\n",
            "Processing files from: /content/drive/My Drive/lifesciences/training_documents\n",
            "Starting: Pharma_URS_Enhanced.docx\n",
            "Converting /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced_temp.docx to /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced.pdf...\n",
            "LibreOffice stdout: convert /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced_temp.docx -> /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced_temp.pdf using filter : writer_pdf_Export\n",
            "\n",
            "Renamed /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced_temp.pdf to /content/drive/My Drive/lifesciences/staging/pdf/Pharma_URS_Enhanced.pdf\n",
            "Saved image: /content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png\n",
            "Saved image: /content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png\n",
            "Detected Type: title, Coordinates: (1292, 1042, 7001, 1845)\n",
            "Detected Type: title, Coordinates: (1298, 2557, 3437, 2916)\n",
            "Detected Type: text, Coordinates: (1483, 3234, 7060, 3364)\n",
            "Detected Type: text, Coordinates: (1511, 3238, 7021, 3505)\n",
            "Detected Type: title, Coordinates: (1307, 3667, 4443, 4002)\n",
            "Detected Type: text, Coordinates: (1739, 4318, 6472, 4450)\n",
            "Detected Type: text, Coordinates: (1300, 4619, 3723, 4943)\n",
            "Skipping overlapping text at (1300, 4619, 3723, 4943) with title\n",
            "Detected Type: title, Coordinates: (1292, 4619, 3732, 4945)\n",
            "Detected Type: list, Coordinates: (1546, 5234, 3770, 5841)\n",
            "Detected Type: title, Coordinates: (1248, 6051, 5840, 6402)\n",
            "Detected Type: text, Coordinates: (1359, 6717, 5839, 6839)\n",
            "Detected Type: title, Coordinates: (1284, 7672, 5442, 8037)\n",
            "Detected Type: list, Coordinates: (1475, 8325, 2994, 8922)\n",
            "Detected Type: text, Coordinates: (1661, 8350, 3019, 8513)\n",
            "Skipping overlapping text at (1661, 8350, 3019, 8513) with list\n",
            "Detected Type: title, Coordinates: (1270, 9132, 5129, 9499)\n",
            "Saved annotated image: /content/drive/My Drive/lifesciences/staging/annotated/Pharma_URS_Enhanced_page_1_annotated.png\n",
            "Detected Type: table, Coordinates: (1165, 994, 7148, 1812)\n",
            "Detected Type: title, Coordinates: (1330, 2139, 5755, 2485)\n",
            "Detected Type: text, Coordinates: (1335, 2796, 5442, 2931)\n",
            "Detected Type: title, Coordinates: (1322, 3069, 5001, 3434)\n",
            "Detected Type: text, Coordinates: (1419, 3078, 4947, 3419)\n",
            "Skipping overlapping text at (1419, 3078, 4947, 3419) with title\n",
            "Detected Type: list, Coordinates: (1427, 3709, 3152, 4336)\n",
            "Detected Type: text, Coordinates: (1300, 4931, 4816, 5290)\n",
            "Skipping overlapping text at (1300, 4931, 4816, 5290) with title\n",
            "Detected Type: title, Coordinates: (1304, 4950, 4811, 5289)\n",
            "Detected Type: table, Coordinates: (1156, 5652, 7153, 6271)\n",
            "Detected Type: title, Coordinates: (1268, 6588, 4131, 6939)\n",
            "Detected Type: text, Coordinates: (1330, 7239, 4847, 7374)\n",
            "Detected Type: title, Coordinates: (1379, 7524, 5694, 7859)\n",
            "Detected Type: table, Coordinates: (1165, 8201, 7132, 8827)\n",
            "Saved annotated image: /content/drive/My Drive/lifesciences/staging/annotated/Pharma_URS_Enhanced_page_2_annotated.png\n",
            "Processed: Pharma_URS_Enhanced.docx, Added 24 entries\n",
            "Processing complete. Total entries: 24\n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 user requirements specification (urs)\n",
            "for pharma industry User Requirements Specification (URS)\n",
            "for Pharma Industry \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 1 introduction 1 Introduction \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 1 introduction This document defines the user requirements for a pharmaceutical manufacturing system to ensure compliance \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 1 introduction This document defines the user requirements for a pharmaceutical manufacturing system to ensure compliance\n",
            "ndustry standards. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 2 system overview 2 System Overview \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 2 system overview The system should support electronic batch records, compliance tracking, and automated reporting. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 3 key features 3 Key Features \n",
            "Combined Text: list Pharma_URS_Enhanced_page_1 3 key features Electronic Batch Records\n",
            " Automated Compliance Checks\n",
            " Realtime Monitoring \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 4 resulatory requirements 4 Resulatory Requirements \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 4 resulatory requirements The system must comply with the following regulations to ensure safe and efficient operations. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 5 applicable regulations 5 Applicable Regulations \n",
            "Combined Text: list Pharma_URS_Enhanced_page_1 5 applicable regulations e FDA 21 CEFR Part 1\n",
            "e EU GMP Annex 11\n",
            "e ICH Q10 \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 6 compliance mapping 6 Compliance Mapping \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 No Title Requirement\n",
            "Electronic-Records\n",
            "Computerized-Systems\n",
            "Test \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 / functional requirements / Functional Requirements \n",
            "Combined Text: text Pharma_URS_Enhanced_page_2 / functional requirements The system must provide the following functionalities for effective pharma operations. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 8 core functionalities 8 Core Functionalities \n",
            "Combined Text: list Pharma_URS_Enhanced_page_2 8 core functionalities e Audit Trails\n",
            "e User Access Control\n",
            "e Automated Reporting \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 9 system capabilities 9 System Capabilities \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 9 system capabilities Function-Description\n",
            "Audit-Trails-Logs-all-changes\n",
            "User-Access-Control-Role-based-permissions \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 10 data integrity 10 Data Integrity \n",
            "Combined Text: text Pharma_URS_Enhanced_page_2 10 data integrity Ensuring data integrity is crucial for compliance and operational accuracy \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 (1 data security measures (1 Data Security Measures \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 (1 data security measures Measure-Implementation\n",
            "Encryption-AES-296\n",
            "Backup-Daily-automatic-backup \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 user requirements specification (urs)\n",
            "for pharma industry User Requirements Specification (URS)\n",
            "for Pharma Industry \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 1 introduction 1 Introduction \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 1 introduction This document defines the user requirements for a pharmaceutical manufacturing system to ensure compliance \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 1 introduction This document defines the user requirements for a pharmaceutical manufacturing system to ensure compliance\n",
            "ndustry standards. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 2 system overview 2 System Overview \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 2 system overview The system should support electronic batch records, compliance tracking, and automated reporting. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 3 key features 3 Key Features \n",
            "Combined Text: list Pharma_URS_Enhanced_page_1 3 key features Electronic Batch Records\n",
            " Automated Compliance Checks\n",
            " Realtime Monitoring \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 4 resulatory requirements 4 Resulatory Requirements \n",
            "Combined Text: text Pharma_URS_Enhanced_page_1 4 resulatory requirements The system must comply with the following regulations to ensure safe and efficient operations. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 5 applicable regulations 5 Applicable Regulations \n",
            "Combined Text: list Pharma_URS_Enhanced_page_1 5 applicable regulations e FDA 21 CEFR Part 1\n",
            "e EU GMP Annex 11\n",
            "e ICH Q10 \n",
            "Combined Text: title Pharma_URS_Enhanced_page_1 6 compliance mapping 6 Compliance Mapping \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 No Title Requirement\n",
            "Electronic-Records\n",
            "Computerized-Systems\n",
            "Test \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 / functional requirements / Functional Requirements \n",
            "Combined Text: text Pharma_URS_Enhanced_page_2 / functional requirements The system must provide the following functionalities for effective pharma operations. \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 8 core functionalities 8 Core Functionalities \n",
            "Combined Text: list Pharma_URS_Enhanced_page_2 8 core functionalities e Audit Trails\n",
            "e User Access Control\n",
            "e Automated Reporting \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 9 system capabilities 9 System Capabilities \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 9 system capabilities Function-Description\n",
            "Audit-Trails-Logs-all-changes\n",
            "User-Access-Control-Role-based-permissions \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 10 data integrity 10 Data Integrity \n",
            "Combined Text: text Pharma_URS_Enhanced_page_2 10 data integrity Ensuring data integrity is crucial for compliance and operational accuracy \n",
            "Combined Text: title Pharma_URS_Enhanced_page_2 (1 data security measures (1 Data Security Measures \n",
            "Combined Text: table Pharma_URS_Enhanced_page_2 (1 data security measures Measure-Implementation\n",
            "Encryption-AES-296\n",
            "Backup-Daily-automatic-backup \n",
            "Generated embeddings for 48 entries\n",
            "Dimension of embeddings: 384\n",
            "FAISS index built with 48 entries and saved to /content/drive/My Drive/lifesciences/faiss_index.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query FAISS Index"
      ],
      "metadata": {
        "id": "mRbjRS7E23Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from fastapi import FastAPI\n",
        "import os\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "FAISS_INDEX_PATH = \"/content/drive/My Drive/lifesciences/faiss_index.index\"\n",
        "METADATA_FILE=\"/content/drive/My Drive/lifesciences/metadata.json\"\n",
        "\n",
        "# Initialize SentenceTransformer\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Loaded SentenceTransformer: all-MiniLM-L6-v2\")\n",
        "\n",
        "def query_faiss_index(urs_name, section_name, content_type, top_k=10):\n",
        "    \"\"\"Query FAISS index with urs_name and section_name, return matching JSON entries\"\"\"\n",
        "    if os.path.exists(FAISS_INDEX_PATH):\n",
        "        faiss_index = faiss.read_index(FAISS_INDEX_PATH)\n",
        "        with open(METADATA_FILE, 'r') as f:\n",
        "            global metadata_entries\n",
        "            metadata_entries = json.load(f)\n",
        "    else:\n",
        "        print(\"FAISS index is empty and no saved index found.\")\n",
        "        return []\n",
        "    query = f\"{content_type} {urs_name} {section_name}\"\n",
        "    print(query)\n",
        "    query_embedding = sentence_model.encode([query], convert_to_numpy=True)\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "    print(f\"distances : {distances}, indices:{indices} number_of_metdata_entries: {len(metadata_entries)}\")\n",
        "    results = [metadata_entries[idx] for idx in indices[0] if idx < len(metadata_entries)]\n",
        "    print(results)\n",
        "    return results\n",
        "\n",
        "# FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/search\")\n",
        "async def search_documents(urs_name: str, section_name: str, content_type :str, top_k: int = 5):\n",
        "    \"\"\"Search FAISS index by urs_name and section_name\"\"\"\n",
        "    results = query_faiss_index(urs_name, section_name,content_type, top_k)\n",
        "    return {\"results\": results}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZlbe810PmB",
        "outputId": "ff54331c-0f35-4213-f31a-1c3fe4560a6d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run UVICORN server and access via NGROK Tunnel"
      ],
      "metadata": {
        "id": "johJd0i7269z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive,userdata\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def run_fastapi_with_ngrok():\n",
        "    \"\"\"Run FastAPI app and expose via ngrok\"\"\"\n",
        "    nest_asyncio.apply()  # Allow running uvicorn in Colab\n",
        "    ngrok.set_auth_token(userdata.get('ngrok_auth_token'))  # Replace with your ngrok auth token\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "run_fastapi_with_ngrok()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mXL5RyHWMbA",
        "outputId": "65e1b903-8eec-4891-b9ce-74531abedc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Public URL: NgrokTunnel: \"https://100e-34-106-83-184.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [27520]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list Pharma_URS_Enhanced_page_2 core functionalities\n",
            "distances : [[0.1613935  0.1613935  0.42887896 0.42887896 0.4900623 ]], indices:[[16 40  6 30 15]] number_of_metdata_entries: 48\n",
            "[{'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 16, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'text', 'content': 'The system must provide the following functionalities for effective pharma operations.', 'coordinates': [1335.11328125, 2796.029296875, 5442.8505859375, 2931.9931640625], 'created_at': '2025-03-10T10:54:20.051739', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=core%20functionalities&content_type=list HTTP/1.1\" 200 OK\n",
            "table Pharma_URS_Enhanced_page_2 data security measures\n",
            "distances : [[0.209436   0.209436   0.43166703 0.43166703 0.45107085]], indices:[[22 46 20 44 23]] number_of_metdata_entries: 48\n",
            "[{'id': 23, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '(1 data security measures\\n\\x0c', 'type': 'title', 'content': '(1 Data Security Measures', 'coordinates': [1379.097900390625, 7524.7587890625, 5694.9453125, 7859.1640625], 'created_at': '2025-03-10T10:54:28.586311', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 23, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '(1 data security measures\\n\\x0c', 'type': 'title', 'content': '(1 Data Security Measures', 'coordinates': [1379.097900390625, 7524.7587890625, 5694.9453125, 7859.1640625], 'created_at': '2025-03-10T10:54:28.586311', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 21, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '10 data integrity\\n\\x0c', 'type': 'title', 'content': '10 Data Integrity', 'coordinates': [1268.370849609375, 6588.73388671875, 4131.4892578125, 6939.71630859375], 'created_at': '2025-03-10T10:54:25.819838', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 21, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '10 data integrity\\n\\x0c', 'type': 'title', 'content': '10 Data Integrity', 'coordinates': [1268.370849609375, 6588.73388671875, 4131.4892578125, 6939.71630859375], 'created_at': '2025-03-10T10:54:25.819838', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 24, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '(1 data security measures\\n\\x0c', 'type': 'table', 'content': 'Measure-Implementation\\nEncryption-AES-296\\nBackup-Daily-automatic-backup', 'coordinates': [1165.436767578125, 8201.7626953125, 7132.7626953125, 8827.0185546875], 'created_at': '2025-03-10T10:54:30.242828', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=data%20security%20measures&content_type=table HTTP/1.1\" 200 OK\n",
            "list Pharma_URS_Enhanced_page_2 core functionalities\n",
            "distances : [[0.1613935  0.1613935  0.42887896 0.42887896 0.4900623 ]], indices:[[16 40  6 30 15]] number_of_metdata_entries: 48\n",
            "[{'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 16, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'text', 'content': 'The system must provide the following functionalities for effective pharma operations.', 'coordinates': [1335.11328125, 2796.029296875, 5442.8505859375, 2931.9931640625], 'created_at': '2025-03-10T10:54:20.051739', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=core%20functionalities&content_type=list HTTP/1.1\" 200 OK\n",
            "list Pharma_URS_Enhanced_page_2 core functionalities\n",
            "distances : [[0.1613935  0.1613935  0.42887896 0.42887896 0.4900623  0.4900623\n",
            "  0.49546382 0.49546382 0.5028527  0.5028527 ]], indices:[[16 40  6 30 15 39 14 38  4 28]] number_of_metdata_entries: 48\n",
            "[{'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 7, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '3 key features\\n\\x0c', 'type': 'title', 'content': '3 Key Features', 'coordinates': [1292.965576171875, 4619.2587890625, 3732.690673828125, 4945.7666015625], 'created_at': '2025-03-10T10:53:48.821543', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 16, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'text', 'content': 'The system must provide the following functionalities for effective pharma operations.', 'coordinates': [1335.11328125, 2796.029296875, 5442.8505859375, 2931.9931640625], 'created_at': '2025-03-10T10:54:20.051739', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 16, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'text', 'content': 'The system must provide the following functionalities for effective pharma operations.', 'coordinates': [1335.11328125, 2796.029296875, 5442.8505859375, 2931.9931640625], 'created_at': '2025-03-10T10:54:20.051739', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 15, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'title', 'content': '/ Functional Requirements', 'coordinates': [1330.021484375, 2139.4267578125, 5755.0029296875, 2485.924560546875], 'created_at': '2025-03-10T10:54:19.286124', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 15, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '/ functional requirements\\n\\x0c', 'type': 'title', 'content': '/ Functional Requirements', 'coordinates': [1330.021484375, 2139.4267578125, 5755.0029296875, 2485.924560546875], 'created_at': '2025-03-10T10:54:19.286124', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 5, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '2 system overview\\n\\x0c', 'type': 'title', 'content': '2 System Overview', 'coordinates': [1307.86865234375, 3667.5673828125, 4443.23291015625, 4002.7294921875], 'created_at': '2025-03-10T10:53:47.296126', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}, {'id': 5, 'urs': 'Pharma_URS_Enhanced_page_1', 'section': '2 system overview\\n\\x0c', 'type': 'title', 'content': '2 System Overview', 'coordinates': [1307.86865234375, 3667.5673828125, 4443.23291015625, 4002.7294921875], 'created_at': '2025-03-10T10:53:47.296126', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_1.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=core%20functionalities&content_type=list&top_k=10 HTTP/1.1\" 200 OK\n",
            "list Pharma_URS_Enhanced_page_2 core functionalities\n",
            "distances : [[0.1613935]], indices:[[16]] number_of_metdata_entries: 48\n",
            "[{'id': 17, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '8 core functionalities\\n\\x0c', 'type': 'title', 'content': '8 Core Functionalities', 'coordinates': [1322.971435546875, 3069.854248046875, 5001.3017578125, 3434.02587890625], 'created_at': '2025-03-10T10:54:21.031137', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=core%20functionalities&content_type=list&top_k=1 HTTP/1.1\" 200 OK\n",
            "table Pharma_URS_Enhanced_page_2 system capabilities\n",
            "distances : [[0.47230732]], indices:[[18]] number_of_metdata_entries: 48\n",
            "[{'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=system%20capabilities&content_type=table&top_k=1 HTTP/1.1\" 200 OK\n",
            "table Pharma_URS_Enhanced_page_2 system capabilities\n",
            "distances : [[0.47230732 0.47230732 0.50065017 0.50065017]], indices:[[18 42 19 43]] number_of_metdata_entries: 48\n",
            "[{'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 20, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'table', 'content': 'Function-Description\\nAudit-Trails-Logs-all-changes\\nUser-Access-Control-Role-based-permissions', 'coordinates': [1156.24462890625, 5652.68896484375, 7153.4033203125, 6271.00537109375], 'created_at': '2025-03-10T10:54:24.550683', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 20, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'table', 'content': 'Function-Description\\nAudit-Trails-Logs-all-changes\\nUser-Access-Control-Role-based-permissions', 'coordinates': [1156.24462890625, 5652.68896484375, 7153.4033203125, 6271.00537109375], 'created_at': '2025-03-10T10:54:24.550683', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=system%20capabilities&content_type=table&top_k=4 HTTP/1.1\" 200 OK\n",
            "table Pharma_URS_Enhanced_page_2 system capabilities\n",
            "distances : [[0.47230732 0.47230732 0.50065017 0.50065017]], indices:[[18 42 19 43]] number_of_metdata_entries: 48\n",
            "[{'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 20, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'table', 'content': 'Function-Description\\nAudit-Trails-Logs-all-changes\\nUser-Access-Control-Role-based-permissions', 'coordinates': [1156.24462890625, 5652.68896484375, 7153.4033203125, 6271.00537109375], 'created_at': '2025-03-10T10:54:24.550683', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}, {'id': 20, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'table', 'content': 'Function-Description\\nAudit-Trails-Logs-all-changes\\nUser-Access-Control-Role-based-permissions', 'coordinates': [1156.24462890625, 5652.68896484375, 7153.4033203125, 6271.00537109375], 'created_at': '2025-03-10T10:54:24.550683', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=system%20capabilities&content_type=table&top_k=4 HTTP/1.1\" 200 OK\n",
            "table Pharma_URS_Enhanced_page_2 system capabilities\n",
            "distances : [[0.47230732]], indices:[[18]] number_of_metdata_entries: 48\n",
            "[{'id': 19, 'urs': 'Pharma_URS_Enhanced_page_2', 'section': '9 system capabilities\\n\\x0c', 'type': 'title', 'content': '9 System Capabilities', 'coordinates': [1304.2999267578125, 4950.44775390625, 4811.6806640625, 5289.10302734375], 'created_at': '2025-03-10T10:54:22.767602', 'source_file': '/content/drive/My Drive/lifesciences/staging/images/Pharma_URS_Enhanced_page_2.png'}]\n",
            "INFO:     176.3.36.142:0 - \"GET /search?urs_name=Pharma_URS_Enhanced_page_2&section_name=system%20capabilities&content_type=table&top_k=1 HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4vn1co0z49D",
        "outputId": "918c3936-9fca-45cf-bd01-5450339de5a9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lart /root/.torch/iopath_cache/s/57zjbwv6gh3srry/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2gyqUqiLXWP",
        "outputId": "2ae500b2-85a3-4239-c6da-ce7d63995493"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1672432\n",
            "-rw-r--r-- 1 root root         0 Mar 10 09:46 'model_final.pth?dl=1.lock'\n",
            "drwxr-xr-x 4 root root      4096 Mar 10 09:46  \u001b[0m\u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 856276388 Mar 10 09:50  model_final.pth\n",
            "-rw-r--r-- 1 root root 856276388 Mar 10 09:52 'model_final.pth?dl=1'\n",
            "drwxr-xr-x 2 root root      4096 Mar 10 09:52  \u001b[01;34m.\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lart /root/.torch/iopath_cache/s/57zjbwv6gh3srry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udnWgVijbRxh",
        "outputId": "738270f9-10a2-461b-f21b-310df426de1a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1672432\n",
            "-rw-r--r-- 1 root root         0 Mar 10 09:46 'model_final.pth?dl=1.lock'\n",
            "drwxr-xr-x 4 root root      4096 Mar 10 09:46  \u001b[0m\u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 856276388 Mar 10 09:50  model_final.pth\n",
            "-rw-r--r-- 1 root root 856276388 Mar 10 09:52 'model_final.pth?dl=1'\n",
            "drwxr-xr-x 2 root root      4096 Mar 10 09:52  \u001b[01;34m.\u001b[0m/\n"
          ]
        }
      ]
    }
  ]
}