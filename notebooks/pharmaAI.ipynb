{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25d397f6aff74e70be855a82a98d0505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b122fdf3ec234a83a8783871e9899798",
              "IPY_MODEL_92df1458722f43ed9d067992baa282aa",
              "IPY_MODEL_3d0a2e4bc60a486595db8b3ed84f8f74"
            ],
            "layout": "IPY_MODEL_7d552448cbec447ab6cff543eee140ab"
          }
        },
        "b122fdf3ec234a83a8783871e9899798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb6d8e06aba4ef4969f71746953eda9",
            "placeholder": "​",
            "style": "IPY_MODEL_0f4493a1ed89436fa01d89cdd03f02e0",
            "value": "Fetching 9 files: 100%"
          }
        },
        "92df1458722f43ed9d067992baa282aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84fcc3b315c467c9a37d3fd973d853a",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e8184db1a414495a4884f7688212df0",
            "value": 9
          }
        },
        "3d0a2e4bc60a486595db8b3ed84f8f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91b5e21a7be405582f5409b8b6b6ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_a7212e29b81c4cdaab6c7fbac60b4790",
            "value": " 9/9 [00:00&lt;00:00,  9.22it/s]"
          }
        },
        "7d552448cbec447ab6cff543eee140ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb6d8e06aba4ef4969f71746953eda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4493a1ed89436fa01d89cdd03f02e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84fcc3b315c467c9a37d3fd973d853a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e8184db1a414495a4884f7688212df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c91b5e21a7be405582f5409b8b6b6ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7212e29b81c4cdaab6c7fbac60b4790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "25d397f6aff74e70be855a82a98d0505",
            "b122fdf3ec234a83a8783871e9899798",
            "92df1458722f43ed9d067992baa282aa",
            "3d0a2e4bc60a486595db8b3ed84f8f74",
            "7d552448cbec447ab6cff543eee140ab",
            "beb6d8e06aba4ef4969f71746953eda9",
            "0f4493a1ed89436fa01d89cdd03f02e0",
            "a84fcc3b315c467c9a37d3fd973d853a",
            "8e8184db1a414495a4884f7688212df0",
            "c91b5e21a7be405582f5409b8b6b6ab6",
            "a7212e29b81c4cdaab6c7fbac60b4790"
          ]
        },
        "id": "T2PTvHbZlrqd",
        "outputId": "00a18a18-a33c-4d31-e9a7-5a9df678f55c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.8)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.27.0)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.11/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.2.2)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.27.0->google-colab) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.27.0->google-colab) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.27.0->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (24.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.67.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (3.1.5)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.45.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.27.0->google-colab) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google-colab) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.8.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.1)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-5a08a3ce5788>:376: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "INFO:     Started server process [6256]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Entering initialize() method\n",
            "Entering _auth_huggingface() method\n",
            "Hugging Face authentication successful.\n",
            "Exiting _auth_huggingface() method\n",
            "Entering _download_model() method\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:832: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25d397f6aff74e70be855a82a98d0505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded to /content/drive/MyDrive/lifesciences/models/DeepSeek-R1-Distill-Qwen-1.5B\n",
            "Entering _load_llm() method\n",
            "LLM loaded successfully\n",
            "Exiting _load_llm() method\n",
            "Entering _load_embedding_model() method\n",
            "Embedding model loaded\n",
            "Exiting _load_embedding_model() method\n",
            "Entering _process_knowledge_base() method\n",
            "Entering _chunk_documents() method\n",
            "Entering _get_docx_files() method\n",
            "Entering _read_docx() method for /content/drive/MyDrive/lifesciences/training_documents/ProtonGlow_Test_URS (1).docx\n",
            "Entering _clean_text() method\n",
            "Entering _token_based_chunking() method\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2487177 > 16384). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text has 2487177 tokens, which exceeds model's max length of 16384. Chunking will occur.\n",
            "Total number of chunks: 5384\n",
            "Exiting _token_based_chunking() method\n",
            "Entering _create_embeddings() method\n",
            "Entering _create_faiss_index() method\n",
            "FAISS index created with 5384 vectors\n",
            "Exiting _create_faiss_index() method\n",
            "Processed 5384 knowledge chunks\n",
            "Exiting _process_knowledge_base() method\n",
            "Exiting initialize() method\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API available at: NgrokTunnel: \"https://554c-34-124-175-170.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-01-30T18:06:08+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entering _find_similar_documents() method\n",
            "Error during document retrieval: tuple index out of range\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entering generate_response() method\n",
            "INFO:     95.223.75.30:0 - \"POST /query?query=%22The%20SCADA%20system%20should%20support%20quality%20control%20%22 HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch torchvision --no-cache-dir\n",
        "!pip install numpy google-colab huggingface_hub python-docx fastapi pyngrok uvicorn nest_asyncio sentence-transformers faiss-cpu datasets --no-cache-dir\n",
        "!pip install -U bitsandbytes transformers\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login, snapshot_download\n",
        "from docx import Document\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from fastapi import FastAPI\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from typing import List\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configuration\n",
        "KB_PATH = '/content/drive/MyDrive/lifesciences/training_documents/'\n",
        "DRIVE_MODEL_PATH = '/content/drive/MyDrive/lifesciences/models/'\n",
        "MODEL_REPO_ID = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "\n",
        "# Constants\n",
        "CHUNK_SIZE = 512  # In tokens\n",
        "CHUNK_OVERLAP = 50\n",
        "SIMILARITY_THRESHOLD = 0.65\n",
        "MAX_CONTEXT_LENGTH = 3000\n",
        "\n",
        "# ----------------------------\n",
        "# Initialization (Run once)\n",
        "# ----------------------------\n",
        "class RAGSystem:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.embedding_model = None\n",
        "        self.index = None\n",
        "        self.chunks = []\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"One-time initialization of all components\"\"\"\n",
        "        print(\"Entering initialize() method\")\n",
        "        try:\n",
        "            self._auth_huggingface()\n",
        "            model_path = self._download_model()\n",
        "            self._load_llm(model_path)\n",
        "            self._load_embedding_model()\n",
        "            self._process_knowledge_base()\n",
        "        except Exception as e:\n",
        "            print(f\"Error during initialization: {str(e)}\")\n",
        "        print(\"Exiting initialize() method\")\n",
        "\n",
        "    def _auth_huggingface(self):\n",
        "        \"\"\"Authenticate with Hugging Face\"\"\"\n",
        "        print(\"Entering _auth_huggingface() method\")\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            login(token=userdata.get(\"HF_TOKEN\"))\n",
        "            print(\"Hugging Face authentication successful.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Authentication failed: {str(e)}\")\n",
        "            raise\n",
        "        print(\"Exiting _auth_huggingface() method\")\n",
        "\n",
        "    def _download_model(self):\n",
        "        \"\"\"Download model from Hugging Face Hub to a new folder inside models\"\"\"\n",
        "        print(\"Entering _download_model() method\")\n",
        "        try:\n",
        "            model_folder = os.path.join(DRIVE_MODEL_PATH, MODEL_REPO_ID.split('/')[-1])\n",
        "            os.makedirs(model_folder, exist_ok=True)\n",
        "\n",
        "            model_path = snapshot_download(\n",
        "                repo_id=MODEL_REPO_ID,\n",
        "                cache_dir=model_folder,\n",
        "                revision=\"main\",\n",
        "                ignore_patterns=[\"*.msgpack\", \"*.h5\", \"*.ot\"],\n",
        "                local_dir=model_folder,\n",
        "                local_dir_use_symlinks=False\n",
        "            )\n",
        "            print(f\"Model downloaded to {model_path}\")\n",
        "            return model_path\n",
        "        except Exception as e:\n",
        "            print(f\"Model download failed: {str(e)}\")\n",
        "            raise\n",
        "        print(\"Exiting _download_model() method\")\n",
        "\n",
        "    def _load_llm(self, model_path):\n",
        "        \"\"\"Load LLM with quantization\"\"\"\n",
        "        print(\"Entering _load_llm() method\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "            bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_path,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                trust_remote_code=True,\n",
        "                quantization_config=bnb_config\n",
        "            )\n",
        "            print(\"LLM loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Model loading failed: {str(e)}\")\n",
        "            raise\n",
        "        print(\"Exiting _load_llm() method\")\n",
        "\n",
        "    def _load_embedding_model(self):\n",
        "        \"\"\"Load sentence transformer model\"\"\"\n",
        "        print(\"Entering _load_embedding_model() method\")\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('thenlper/gte-base')\n",
        "            print(\"Embedding model loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"Embedding model loading failed: {str(e)}\")\n",
        "            raise\n",
        "        print(\"Exiting _load_embedding_model() method\")\n",
        "\n",
        "    def _process_knowledge_base(self):\n",
        "        \"\"\"Process documents and create FAISS index\"\"\"\n",
        "        print(\"Entering _process_knowledge_base() method\")\n",
        "        try:\n",
        "            self.chunks = self._chunk_documents()\n",
        "            embeddings = self._create_embeddings(self.chunks)\n",
        "            self._create_faiss_index(embeddings)\n",
        "            print(f\"Processed {len(self.chunks)} knowledge chunks\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing knowledge base: {str(e)}\")\n",
        "            raise\n",
        "        print(\"Exiting _process_knowledge_base() method\")\n",
        "\n",
        "    def _chunk_documents(self) -> List[str]:\n",
        "        \"\"\"Improved document chunking with text cleaning\"\"\"\n",
        "        print(\"Entering _chunk_documents() method\")\n",
        "        try:\n",
        "            chunks = []\n",
        "            for doc_path in self._get_docx_files():\n",
        "                content = self._read_docx(doc_path)\n",
        "                content = self._clean_text(content)\n",
        "                chunks.extend(self._token_based_chunking(content))\n",
        "            return chunks\n",
        "        except Exception as e:\n",
        "            print(f\"Error during chunking documents: {str(e)}\")\n",
        "            return []\n",
        "        print(\"Exiting _chunk_documents() method\")\n",
        "\n",
        "    def _get_docx_files(self):\n",
        "        \"\"\"Get all DOCX files from knowledge base path\"\"\"\n",
        "        print(\"Entering _get_docx_files() method\")\n",
        "        try:\n",
        "            return [os.path.join(KB_PATH, f) for f in os.listdir(KB_PATH) if f.endswith('.docx')]\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving DOCX files: {str(e)}\")\n",
        "            return []\n",
        "        print(\"Exiting _get_docx_files() method\")\n",
        "\n",
        "    def _read_docx(self, file_path: str) -> str:\n",
        "        \"\"\"Read DOCX file with paragraphs and tables, with error handling, maintaining section headings with tables.\"\"\"\n",
        "        print(f\"Entering _read_docx() method for {file_path}\")\n",
        "        try:\n",
        "            doc = Document(file_path)\n",
        "            content = []\n",
        "            temp_section = \"\"\n",
        "\n",
        "            for para in doc.paragraphs:\n",
        "                if para.style and para.style.name.startswith(\"Heading\"):\n",
        "                    if temp_section:\n",
        "                        content.append(temp_section.strip())\n",
        "                    temp_section = para.text.strip()\n",
        "                else:\n",
        "                    temp_section += \"\\n\" + para.text.strip()\n",
        "\n",
        "                for table in doc.tables:\n",
        "                    if table._element.getparent() == para._element.getparent():\n",
        "                        table_text = \"\"\n",
        "                        for row in table.rows:\n",
        "                            row_text = \"\\t\".join(cell.text.strip() for cell in row.cells if cell.text.strip())\n",
        "                            if row_text:\n",
        "                                table_text += row_text + \"\\n\"\n",
        "                        temp_section += \"\\n\" + table_text.strip()\n",
        "\n",
        "            if temp_section:\n",
        "                content.append(temp_section.strip())\n",
        "\n",
        "            return \"\\n\\n\".join(content).strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "        print(f\"Exiting _read_docx() method for {file_path}\")\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        print(\"Entering _clean_text() method\")\n",
        "        try:\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "            text = re.sub(r'\\u200b', '', text)\n",
        "            return text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error cleaning text: {str(e)}\")\n",
        "            return text\n",
        "        print(\"Exiting _clean_text() method\")\n",
        "\n",
        "    def _token_based_chunking(self, text: str) -> List[str]:\n",
        "        \"\"\"Token-based chunking with overlap, ensuring chunks don't exceed max length\"\"\"\n",
        "        print(\"Entering _token_based_chunking() method\")\n",
        "        try:\n",
        "            # Tokenize the text into tokens\n",
        "            tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
        "            num_tokens = len(tokens)\n",
        "\n",
        "            # Get the model's max token length (adjust this value based on your model)\n",
        "            max_length = self.tokenizer.model_max_length\n",
        "\n",
        "            # If tokens exceed max_length, we need to chunk them\n",
        "            if num_tokens > max_length:\n",
        "                print(f\"Input text has {num_tokens} tokens, which exceeds model's max length of {max_length}. Chunking will occur.\")\n",
        "\n",
        "            # Initialize chunks list\n",
        "            chunks = []\n",
        "\n",
        "            # Create chunks with overlap, ensuring each chunk is smaller than max_length\n",
        "            for start in range(0, num_tokens, CHUNK_SIZE - CHUNK_OVERLAP):\n",
        "                end = min(start + CHUNK_SIZE, num_tokens)\n",
        "\n",
        "                # Make sure we don't exceed max token length\n",
        "                if end - start > max_length:\n",
        "                    print(f\"Truncating chunk: start={start}, end={end}, chunk_size={end - start} exceeds max length!\")\n",
        "                    end = start + max_length\n",
        "\n",
        "                chunk_tokens = tokens[start:end]\n",
        "                chunk = self.tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
        "                chunks.append(chunk)\n",
        "\n",
        "                # Optional: Log chunk size for debugging\n",
        "                #print(f\"Chunk {len(chunks)}: {len(chunk_tokens)} tokens (start: {start}, end: {end})\")\n",
        "\n",
        "            # Final number of chunks\n",
        "            print(f\"Total number of chunks: {len(chunks)}\")\n",
        "\n",
        "            return chunks\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during token-based chunking: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "        finally:\n",
        "            print(\"Exiting _token_based_chunking() method\")\n",
        "\n",
        "\n",
        "    def _create_embeddings(self, chunks: List[str]):\n",
        "        \"\"\"Create embeddings with batching and memory management.\"\"\"\n",
        "        print(\"Entering _create_embeddings() method\")\n",
        "        try:\n",
        "            embeddings = []\n",
        "            batch_size = 64\n",
        "\n",
        "            for i in range(0, len(chunks), batch_size):\n",
        "                batch = chunks[i:i+batch_size]\n",
        "                emb = self.embedding_model.encode(batch, show_progress_bar=False)\n",
        "                embeddings.append(emb)\n",
        "                del batch\n",
        "                gc.collect()\n",
        "\n",
        "            if embeddings:\n",
        "                return np.vstack(embeddings)\n",
        "            else:\n",
        "                print(\"No embeddings were generated.\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating embeddings: {str(e)}\")\n",
        "            return None\n",
        "        print(\"Exiting _create_embeddings() method\")\n",
        "\n",
        "    def _create_faiss_index(self, embeddings: np.ndarray):\n",
        "        \"\"\"Create optimized FAISS index\"\"\"\n",
        "        print(\"Entering _create_faiss_index() method\")\n",
        "        try:\n",
        "            dimension = embeddings.shape[1]\n",
        "            self.index = faiss.IndexFlatIP(dimension)\n",
        "            faiss.normalize_L2(embeddings)\n",
        "            self.index.add(embeddings)\n",
        "            print(f\"FAISS index created with {self.index.ntotal} vectors\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating FAISS index: {str(e)}\")\n",
        "        print(\"Exiting _create_faiss_index() method\")\n",
        "\n",
        "    def _find_similar_documents(self, query: str) -> str:\n",
        "          \"\"\"Find the most relevant chunks from the knowledge base based on query similarity\"\"\"\n",
        "          print(\"Entering _find_similar_documents() method\")\n",
        "          try:\n",
        "              # Encode the query to get its embedding\n",
        "              query_embedding = self.embedding_model.encode([query])[0]\n",
        "\n",
        "              # Normalize the query embedding (FAISS requires normalized vectors)\n",
        "              faiss.normalize_L2(query_embedding)\n",
        "\n",
        "              # Perform the FAISS search for the most similar documents\n",
        "              distances, indices = self.index.search(np.array([query_embedding]), k=5)\n",
        "\n",
        "              # Check if the search returned valid indices and distances\n",
        "              if distances is None or indices is None:\n",
        "                  print(\"Error: FAISS search returned None for distances or indices.\")\n",
        "                  return \"Sorry, I couldn't find any relevant documents.\"\n",
        "\n",
        "              if len(indices) == 0 or len(indices[0]) == 0:\n",
        "                  print(\"No similar documents found.\")\n",
        "                  return \"Sorry, no similar documents were found.\"\n",
        "\n",
        "              # Log the top 5 results for debugging purposes\n",
        "              print(f\"Top 5 similar documents (indices): {indices[0]}\")\n",
        "              print(f\"Top 5 distances: {distances[0]}\")\n",
        "\n",
        "              # Fetch the context for the top results (ensure indices are valid)\n",
        "              context = \"\\n\\n\".join([self.chunks[i] for i in indices[0] if i < len(self.chunks)])\n",
        "\n",
        "              # If no valid context is found, return a fallback message\n",
        "              if not context:\n",
        "                  print(\"Error: No valid context found for the top indices.\")\n",
        "                  return \"Sorry, no relevant context could be retrieved.\"\n",
        "\n",
        "              return context\n",
        "\n",
        "          except Exception as e:\n",
        "              # Catch any unexpected errors and log them for debugging\n",
        "              print(f\"Error during document retrieval: {str(e)}\")\n",
        "              return \"Sorry, there was an error while processing your request.\"\n",
        "\n",
        "          finally:\n",
        "              # Clean up any unnecessary variables to free memory\n",
        "              del query_embedding\n",
        "              gc.collect()\n",
        "\n",
        "          print(\"Exiting _find_similar_documents() method\")\n",
        "\n",
        "\n",
        "\n",
        "    def generate_response(self, query: str, context: str) -> str:\n",
        "      \"\"\"Generate a response by feeding the query and context into the language model\"\"\"\n",
        "      print(\"Entering generate_response() method\")\n",
        "      try:\n",
        "          full_input = f\"Query: {query}\\nContext: {context}\"\n",
        "          if len(full_input) > MAX_CONTEXT_LENGTH:\n",
        "              full_input = full_input[:MAX_CONTEXT_LENGTH]\n",
        "\n",
        "          # Tokenize the input\n",
        "          inputs = self.tokenizer(full_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "          # Ensure the input tensor is on the same device as the model (GPU)\n",
        "          device = self.model.device  # Get model's device\n",
        "          inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as model\n",
        "\n",
        "          # Generate output\n",
        "          outputs = self.model.generate(**inputs, max_length=1024)\n",
        "          response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "          return response\n",
        "      except Exception as e:\n",
        "          print(f\"Error generating response: {str(e)}\")\n",
        "          return \"Sorry, I couldn't generate a response.\"\n",
        "      print(\"Exiting generate_response() method\")\n",
        "\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    rag_system.initialize()\n",
        "    ngrok.set_auth_token(userdata.get(\"ngrok_auth_token\"))\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"API available at: {public_url}\")\n",
        "\n",
        "@app.post(\"/query\")\n",
        "async def handle_query(query: str):\n",
        "    try:\n",
        "        if len(query) < 3:\n",
        "            return {\"error\": \"Query too short\"}\n",
        "\n",
        "        context = rag_system._find_similar_documents(query)\n",
        "        response = rag_system.generate_response(query, context)\n",
        "        return {\"response\": response}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run FastAPI server\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # ----------------------------\n",
        "    # FastAPI Application\n",
        "  #----------------------------\n",
        "  rag_system = RAGSystem()\n",
        "  main()\n"
      ]
    }
  ]
}