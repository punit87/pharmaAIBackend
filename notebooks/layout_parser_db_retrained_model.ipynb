{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZxbFeAzDUnD",
        "outputId": "83c99bf3-8160-4c08-a713-457a6873a41c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y libreoffice poppler-utils tesseract-ocr -qq  # For DOCX to PDF, pdf2image, and OCR\n",
        "\n",
        "# Clean up existing torch-related packages to avoid conflicts\n",
        "#!pip uninstall torch torchaudio torchvision fastai layoutparser detectron2 fvcore -y --quiet\n",
        "\n",
        "# Install latest Python dependencies\n",
        "!pip install torch torchvision pdf2image opencv-python layoutparser pytesseract --quiet\n",
        "\n",
        "# Install prerequisites for detectron2\n",
        "!pip install cython pycocotools fvcore --quiet\n",
        "\n",
        "# Install detectron2 from source (compatible with torch 2.6.0+cu124)\n",
        "#!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "!pip install python-docx\n",
        "!pip install --upgrade pillow\n",
        "!sudo apt-get install tesseract-ocr-eng\n",
        "#!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.5#egg=detectron2\"\n",
        "!pip install -U 'git+https://github.com/facebookresearch/detectron2.git@ff53992b1985b63bd3262b5a36167098e3dada02'\n",
        "!pip install \"layoutparser[ocr]\"\n",
        "\n",
        "!pip install sentence-transformers faiss-cpu  fastapi uvicorn pyngrok\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv4kDCeRQVbo",
        "outputId": "290c811a-2c12-466a-b9bb-91f40c6fcd9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git@ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision ff53992b1985b63bd3262b5a36167098e3dada02) to /tmp/pip-req-build-1f41g4s5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-1f41g4s5\n",
            "  Running command git rev-parse -q --verify 'sha^ff53992b1985b63bd3262b5a36167098e3dada02'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Running command git checkout -q ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit ff53992b1985b63bd3262b5a36167098e3dada02\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: layoutparser[ocr] in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (6.0.2)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.1.9)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.11.5)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.17.0)\n",
            "Requirement already satisfied: google-cloud-vision==1 in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (1.0.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (from layoutparser[ocr]) (0.3.13)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.34.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->layoutparser[ocr]) (4.67.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->layoutparser[ocr]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser[ocr]) (2025.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber->layoutparser[ocr]) (20231228)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber->layoutparser[ocr]) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract->layoutparser[ocr]) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.69.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (1.48.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->layoutparser[ocr]) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (4.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[ocr]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (0.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.11)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKFGNVg1CB3D",
        "outputId": "22edf07b-0808-42e9-ece0-21c38789cec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mon Mar 17 14:06:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             34W /   70W |    7382MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "Actual images in /content/drive/My Drive/lifesciences/post_label/images: ['dba943c5-ProtonGlow_Test_URS_1_page_14.png', '32b16166-ProtonGlow_Test_URS_1_page_34.png', 'c77134ed-ProtonGlow_Test_URS_1_page_26.png', '2124bdf9-ProtonGlow_Test_URS_1_page_5.png', 'f7c3a644-ProtonGlow_Test_URS_1_page_16.png', 'f19c46f0-ProtonGlow_Test_URS_1_page_30.png', 'fe7aa29b-ProtonGlow_Test_URS_1_page_32.png', 'c8aa0be3-ProtonGlow_Test_URS_1_page_7.png', '042f030e-ProtonGlow_Test_URS_1_page_9.png', '3f57eebd-ProtonGlow_Test_URS_1_page_19.png', '7347d622-ProtonGlow_Test_URS_1_page_20.png', '245272e6-ProtonGlow_Test_URS_1_page_28.png', '426fb557-Pharma_URS_Enhanced_page_1.png', '5e5d7ccd-ProtonGlow_Test_URS_1_page_10.png', '68b58f6d-ProtonGlow_Test_URS_1_page_15.png', 'c9df1740-ProtonGlow_Test_URS_1_page_12.png', 'eddd6c38-ProtonGlow_Test_URS_1_page_29.png', '48759adc-Pharma_URS_Enhanced_page_2.png', '48ed3ccf-ProtonGlow_Test_URS_1_page_31.png', '148a3bf9-ProtonGlow_Test_URS_1_page_2.png', 'ea5776e7-ProtonGlow_Test_URS_1_page_6.png', '776ef5f2-ProtonGlow_Test_URS_1_page_8.png', '043f5478-ProtonGlow_Test_URS_1_page_21.png', '9751783c-ProtonGlow_Test_URS_1_page_18.png', 'd39b2cf1-ProtonGlow_Test_URS_1_page_33.png', '7226722b-ProtonGlow_Test_URS_1_page_25.png', '046cbd69-ProtonGlow_Test_URS_1_page_27.png', 'a83b124d-ProtonGlow_Test_URS_1_page_13.png', '58cd0367-ProtonGlow_Test_URS_1_page_11.png', 'b20e4d9c-ProtonGlow_Test_URS_1_page_24.png', 'e5433553-ProtonGlow_Test_URS_1_page_4.png', 'ee1322e1-ProtonGlow_Test_URS_1_page_22.png', 'bb38c851-ProtonGlow_Test_URS_1_page_3.png', 'aa67a5ad-ProtonGlow_Test_URS_1_page_23.png', 'f75fe9c4-ProtonGlow_Test_URS_1_page_17.png']\n",
            "Mapped ./images/426fb557-Pharma_URS_Enhanced_page_1.png to /content/drive/My Drive/lifesciences/post_label/images/426fb557-Pharma_URS_Enhanced_page_1.png\n",
            "Mapped ./images/48759adc-Pharma_URS_Enhanced_page_2.png to /content/drive/My Drive/lifesciences/post_label/images/48759adc-Pharma_URS_Enhanced_page_2.png\n",
            "Mapped ./images/148a3bf9-ProtonGlow_Test_URS_1_page_2.png to /content/drive/My Drive/lifesciences/post_label/images/148a3bf9-ProtonGlow_Test_URS_1_page_2.png\n",
            "Mapped ./images/bb38c851-ProtonGlow_Test_URS_1_page_3.png to /content/drive/My Drive/lifesciences/post_label/images/bb38c851-ProtonGlow_Test_URS_1_page_3.png\n",
            "Mapped ./images/e5433553-ProtonGlow_Test_URS_1_page_4.png to /content/drive/My Drive/lifesciences/post_label/images/e5433553-ProtonGlow_Test_URS_1_page_4.png\n",
            "Mapped ./images/2124bdf9-ProtonGlow_Test_URS_1_page_5.png to /content/drive/My Drive/lifesciences/post_label/images/2124bdf9-ProtonGlow_Test_URS_1_page_5.png\n",
            "Mapped ./images/ea5776e7-ProtonGlow_Test_URS_1_page_6.png to /content/drive/My Drive/lifesciences/post_label/images/ea5776e7-ProtonGlow_Test_URS_1_page_6.png\n",
            "Mapped ./images/c8aa0be3-ProtonGlow_Test_URS_1_page_7.png to /content/drive/My Drive/lifesciences/post_label/images/c8aa0be3-ProtonGlow_Test_URS_1_page_7.png\n",
            "Mapped ./images/776ef5f2-ProtonGlow_Test_URS_1_page_8.png to /content/drive/My Drive/lifesciences/post_label/images/776ef5f2-ProtonGlow_Test_URS_1_page_8.png\n",
            "Mapped ./images/042f030e-ProtonGlow_Test_URS_1_page_9.png to /content/drive/My Drive/lifesciences/post_label/images/042f030e-ProtonGlow_Test_URS_1_page_9.png\n",
            "Mapped ./images/5e5d7ccd-ProtonGlow_Test_URS_1_page_10.png to /content/drive/My Drive/lifesciences/post_label/images/5e5d7ccd-ProtonGlow_Test_URS_1_page_10.png\n",
            "Mapped ./images/58cd0367-ProtonGlow_Test_URS_1_page_11.png to /content/drive/My Drive/lifesciences/post_label/images/58cd0367-ProtonGlow_Test_URS_1_page_11.png\n",
            "Mapped ./images/c9df1740-ProtonGlow_Test_URS_1_page_12.png to /content/drive/My Drive/lifesciences/post_label/images/c9df1740-ProtonGlow_Test_URS_1_page_12.png\n",
            "Mapped ./images/a83b124d-ProtonGlow_Test_URS_1_page_13.png to /content/drive/My Drive/lifesciences/post_label/images/a83b124d-ProtonGlow_Test_URS_1_page_13.png\n",
            "Mapped ./images/dba943c5-ProtonGlow_Test_URS_1_page_14.png to /content/drive/My Drive/lifesciences/post_label/images/dba943c5-ProtonGlow_Test_URS_1_page_14.png\n",
            "Mapped ./images/68b58f6d-ProtonGlow_Test_URS_1_page_15.png to /content/drive/My Drive/lifesciences/post_label/images/68b58f6d-ProtonGlow_Test_URS_1_page_15.png\n",
            "Mapped ./images/f7c3a644-ProtonGlow_Test_URS_1_page_16.png to /content/drive/My Drive/lifesciences/post_label/images/f7c3a644-ProtonGlow_Test_URS_1_page_16.png\n",
            "Mapped ./images/f75fe9c4-ProtonGlow_Test_URS_1_page_17.png to /content/drive/My Drive/lifesciences/post_label/images/f75fe9c4-ProtonGlow_Test_URS_1_page_17.png\n",
            "Mapped ./images/9751783c-ProtonGlow_Test_URS_1_page_18.png to /content/drive/My Drive/lifesciences/post_label/images/9751783c-ProtonGlow_Test_URS_1_page_18.png\n",
            "Mapped ./images/3f57eebd-ProtonGlow_Test_URS_1_page_19.png to /content/drive/My Drive/lifesciences/post_label/images/3f57eebd-ProtonGlow_Test_URS_1_page_19.png\n",
            "Mapped ./images/7347d622-ProtonGlow_Test_URS_1_page_20.png to /content/drive/My Drive/lifesciences/post_label/images/7347d622-ProtonGlow_Test_URS_1_page_20.png\n",
            "Mapped ./images/043f5478-ProtonGlow_Test_URS_1_page_21.png to /content/drive/My Drive/lifesciences/post_label/images/043f5478-ProtonGlow_Test_URS_1_page_21.png\n",
            "Mapped ./images/ee1322e1-ProtonGlow_Test_URS_1_page_22.png to /content/drive/My Drive/lifesciences/post_label/images/ee1322e1-ProtonGlow_Test_URS_1_page_22.png\n",
            "Mapped ./images/aa67a5ad-ProtonGlow_Test_URS_1_page_23.png to /content/drive/My Drive/lifesciences/post_label/images/aa67a5ad-ProtonGlow_Test_URS_1_page_23.png\n",
            "Mapped ./images/b20e4d9c-ProtonGlow_Test_URS_1_page_24.png to /content/drive/My Drive/lifesciences/post_label/images/b20e4d9c-ProtonGlow_Test_URS_1_page_24.png\n",
            "Mapped ./images/7226722b-ProtonGlow_Test_URS_1_page_25.png to /content/drive/My Drive/lifesciences/post_label/images/7226722b-ProtonGlow_Test_URS_1_page_25.png\n",
            "Mapped ./images/c77134ed-ProtonGlow_Test_URS_1_page_26.png to /content/drive/My Drive/lifesciences/post_label/images/c77134ed-ProtonGlow_Test_URS_1_page_26.png\n",
            "Mapped ./images/046cbd69-ProtonGlow_Test_URS_1_page_27.png to /content/drive/My Drive/lifesciences/post_label/images/046cbd69-ProtonGlow_Test_URS_1_page_27.png\n",
            "Mapped ./images/245272e6-ProtonGlow_Test_URS_1_page_28.png to /content/drive/My Drive/lifesciences/post_label/images/245272e6-ProtonGlow_Test_URS_1_page_28.png\n",
            "Mapped ./images/eddd6c38-ProtonGlow_Test_URS_1_page_29.png to /content/drive/My Drive/lifesciences/post_label/images/eddd6c38-ProtonGlow_Test_URS_1_page_29.png\n",
            "Mapped ./images/f19c46f0-ProtonGlow_Test_URS_1_page_30.png to /content/drive/My Drive/lifesciences/post_label/images/f19c46f0-ProtonGlow_Test_URS_1_page_30.png\n",
            "Mapped ./images/48ed3ccf-ProtonGlow_Test_URS_1_page_31.png to /content/drive/My Drive/lifesciences/post_label/images/48ed3ccf-ProtonGlow_Test_URS_1_page_31.png\n",
            "Mapped ./images/fe7aa29b-ProtonGlow_Test_URS_1_page_32.png to /content/drive/My Drive/lifesciences/post_label/images/fe7aa29b-ProtonGlow_Test_URS_1_page_32.png\n",
            "Mapped ./images/d39b2cf1-ProtonGlow_Test_URS_1_page_33.png to /content/drive/My Drive/lifesciences/post_label/images/d39b2cf1-ProtonGlow_Test_URS_1_page_33.png\n",
            "Mapped ./images/32b16166-ProtonGlow_Test_URS_1_page_34.png to /content/drive/My Drive/lifesciences/post_label/images/32b16166-ProtonGlow_Test_URS_1_page_34.png\n",
            "Updated COCO JSON saved to /content/drive/My Drive/lifesciences/retrained_staging/results_mapped.json\n",
            "Unregistered existing dataset: custom_layout_dataset\n",
            "Registered dataset: custom_layout_dataset\n",
            "Loaded pre-trained weights from /content/drive/My Drive/lifesciences/models/model_final.pth (Faster R-CNN)\n",
            "[03/17 14:07:03 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/17 14:07:03 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/17 14:07:03 d2.data.datasets.coco]: Loaded 35 images in COCO format from /content/drive/My Drive/lifesciences/retrained_staging/results_mapped.json\n",
            "[03/17 14:07:03 d2.data.build]: Removed 0 images with no usable annotations. 35 images left.\n",
            "[03/17 14:07:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/17 14:07:03 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/17 14:07:03 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/17 14:07:03 d2.data.common]: Serializing 35 elements to byte tensors and concatenating them all ...\n",
            "[03/17 14:07:03 d2.data.common]: Serialized dataset takes 0.02 MiB\n",
            "WARNING [03/17 14:07:03 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/17 14:07:03 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/My Drive/lifesciences/models/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  roi_heads.mask_head.mask_fcn1.{bias, weight}\n",
            "  roi_heads.mask_head.mask_fcn2.{bias, weight}\n",
            "  roi_heads.mask_head.mask_fcn3.{bias, weight}\n",
            "  roi_heads.mask_head.mask_fcn4.{bias, weight}\n",
            "  roi_heads.mask_head.deconv.{bias, weight}\n",
            "  roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/17 14:07:06 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/17 14:07:48 d2.utils.events]:  eta: 0:10:07  iter: 19  total_loss: 1.109  loss_cls: 0.7844  loss_box_reg: 0.1996  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.05679    time: 1.9973  last_time: 2.2545  data_time: 0.1243  last_data_time: 0.0061   lr: 1.6068e-05  max_mem: 5196M\n",
            "[03/17 14:08:25 d2.utils.events]:  eta: 0:08:59  iter: 39  total_loss: 1.29  loss_cls: 0.844  loss_box_reg: 0.2946  loss_rpn_cls: 0.04218  loss_rpn_loc: 0.08576    time: 1.9170  last_time: 1.3280  data_time: 0.0089  last_data_time: 0.0059   lr: 3.2718e-05  max_mem: 5196M\n",
            "[03/17 14:09:01 d2.utils.events]:  eta: 0:08:02  iter: 59  total_loss: 0.4428  loss_cls: 0.2552  loss_box_reg: 0.1198  loss_rpn_cls: 0.04206  loss_rpn_loc: 0.01815    time: 1.8734  last_time: 2.2976  data_time: 0.0063  last_data_time: 0.0060   lr: 4.9367e-05  max_mem: 5196M\n",
            "[03/17 14:09:39 d2.utils.events]:  eta: 0:07:22  iter: 79  total_loss: 0.4373  loss_cls: 0.1808  loss_box_reg: 0.1718  loss_rpn_cls: 0.02911  loss_rpn_loc: 0.03951    time: 1.8849  last_time: 1.1953  data_time: 0.0074  last_data_time: 0.0063   lr: 6.6017e-05  max_mem: 5196M\n",
            "[03/17 14:10:15 d2.utils.events]:  eta: 0:06:39  iter: 99  total_loss: 0.3235  loss_cls: 0.0631  loss_box_reg: 0.1764  loss_rpn_cls: 0.02359  loss_rpn_loc: 0.04867    time: 1.8645  last_time: 1.9954  data_time: 0.0104  last_data_time: 0.0056   lr: 8.2668e-05  max_mem: 5196M\n",
            "[03/17 14:10:51 d2.utils.events]:  eta: 0:05:58  iter: 119  total_loss: 0.2238  loss_cls: 0.04632  loss_box_reg: 0.1257  loss_rpn_cls: 0.01986  loss_rpn_loc: 0.01918    time: 1.8515  last_time: 1.3995  data_time: 0.0075  last_data_time: 0.0065   lr: 9.9318e-05  max_mem: 5196M\n",
            "[03/17 14:11:25 d2.utils.events]:  eta: 0:05:18  iter: 139  total_loss: 0.2293  loss_cls: 0.02878  loss_box_reg: 0.1445  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.02779    time: 1.8308  last_time: 2.0636  data_time: 0.0101  last_data_time: 0.0252   lr: 0.00011597  max_mem: 5196M\n",
            "[03/17 14:12:01 d2.utils.events]:  eta: 0:04:38  iter: 159  total_loss: 0.2016  loss_cls: 0.03204  loss_box_reg: 0.1285  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.03356    time: 1.8288  last_time: 1.9835  data_time: 0.0083  last_data_time: 0.0057   lr: 0.00013262  max_mem: 5196M\n",
            "[03/17 14:12:38 d2.utils.events]:  eta: 0:03:58  iter: 179  total_loss: 0.1834  loss_cls: 0.03358  loss_box_reg: 0.1226  loss_rpn_cls: 0.00828  loss_rpn_loc: 0.03299    time: 1.8327  last_time: 1.5956  data_time: 0.0120  last_data_time: 0.0058   lr: 0.00014927  max_mem: 5196M\n",
            "[03/17 14:13:14 d2.utils.events]:  eta: 0:03:18  iter: 199  total_loss: 0.1702  loss_cls: 0.02779  loss_box_reg: 0.1336  loss_rpn_cls: 0.005508  loss_rpn_loc: 0.01206    time: 1.8266  last_time: 2.2506  data_time: 0.0112  last_data_time: 0.0061   lr: 0.00016592  max_mem: 5196M\n",
            "[03/17 14:13:51 d2.utils.events]:  eta: 0:02:38  iter: 219  total_loss: 0.2254  loss_cls: 0.02565  loss_box_reg: 0.1395  loss_rpn_cls: 0.007728  loss_rpn_loc: 0.02379    time: 1.8279  last_time: 1.3919  data_time: 0.0090  last_data_time: 0.0065   lr: 0.00018257  max_mem: 5196M\n",
            "[03/17 14:14:26 d2.utils.events]:  eta: 0:01:59  iter: 239  total_loss: 0.269  loss_cls: 0.02976  loss_box_reg: 0.1577  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.04615    time: 1.8223  last_time: 1.3803  data_time: 0.0064  last_data_time: 0.0062   lr: 0.00019922  max_mem: 5196M\n",
            "[03/17 14:15:02 d2.utils.events]:  eta: 0:01:19  iter: 259  total_loss: 0.13  loss_cls: 0.01753  loss_box_reg: 0.1034  loss_rpn_cls: 0.006458  loss_rpn_loc: 0.01411    time: 1.8209  last_time: 1.9985  data_time: 0.0101  last_data_time: 0.0059   lr: 0.00021587  max_mem: 5197M\n",
            "[03/17 14:15:39 d2.utils.events]:  eta: 0:00:39  iter: 279  total_loss: 0.2131  loss_cls: 0.02342  loss_box_reg: 0.1474  loss_rpn_cls: 0.004665  loss_rpn_loc: 0.03829    time: 1.8236  last_time: 1.3101  data_time: 0.0086  last_data_time: 0.0064   lr: 0.00023252  max_mem: 5197M\n",
            "[03/17 14:16:21 d2.utils.events]:  eta: 0:00:00  iter: 299  total_loss: 0.2067  loss_cls: 0.02642  loss_box_reg: 0.1282  loss_rpn_cls: 0.007197  loss_rpn_loc: 0.03747    time: 1.8233  last_time: 2.2540  data_time: 0.0082  last_data_time: 0.0091   lr: 0.00024917  max_mem: 5197M\n",
            "[03/17 14:16:21 d2.engine.hooks]: Overall training speed: 298 iterations in 0:09:03 (1.8233 s / it)\n",
            "[03/17 14:16:21 d2.engine.hooks]: Total training time: 0:09:08 (0:00:05 on hooks)\n",
            "[03/17 14:16:22 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/My Drive/lifesciences/retrained_staging/models/model_final.pth ...\n",
            "Model retrained and saved to /content/drive/My Drive/lifesciences/retrained_staging/models/model_final.pth\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/426fb557-Pharma_URS_Enhanced_page_1.png\n",
            "OCR agent loaded\n",
            "Skipping title inside list at coordinates: [332, 300, 2166, 572]\n",
            "Skipping title inside table at coordinates: [389, 951, 2148, 1062]\n",
            "Skipping title inside table at coordinates: [406, 1551, 1174, 1776]\n",
            "Skipping title inside list at coordinates: [414, 2491, 942, 2693]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/426fb557-Pharma_URS_Enhanced_page_1_reannotated.png\n",
            "Connected to Neon PostgreSQL database\n",
            "Started new batch run: 16\n",
            "Inserted 4 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/48759adc-Pharma_URS_Enhanced_page_2.png\n",
            "Skipping title inside table at coordinates: [310, 272, 2223, 564]\n",
            "Skipping title inside list at coordinates: [422, 1101, 971, 1315]\n",
            "Skipping title inside table at coordinates: [328, 1660, 2201, 1900]\n",
            "Skipping title inside list at coordinates: [365, 1965, 1266, 2089]\n",
            "Skipping text inside table at coordinates: [330, 2418, 2201, 2666]\n",
            "Skipping title inside table at coordinates: [332, 2423, 2205, 2664]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/48759adc-Pharma_URS_Enhanced_page_2_reannotated.png\n",
            "Inserted 6 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/148a3bf9-ProtonGlow_Test_URS_1_page_2.png\n",
            "Skipping title inside list at coordinates: [444, 3143, 2205, 3212]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/148a3bf9-ProtonGlow_Test_URS_1_page_2_reannotated.png\n",
            "Inserted 1 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/bb38c851-ProtonGlow_Test_URS_1_page_3.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/bb38c851-ProtonGlow_Test_URS_1_page_3_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/e5433553-ProtonGlow_Test_URS_1_page_4.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/e5433553-ProtonGlow_Test_URS_1_page_4_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/2124bdf9-ProtonGlow_Test_URS_1_page_5.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/2124bdf9-ProtonGlow_Test_URS_1_page_5_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/ea5776e7-ProtonGlow_Test_URS_1_page_6.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/ea5776e7-ProtonGlow_Test_URS_1_page_6_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/c8aa0be3-ProtonGlow_Test_URS_1_page_7.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/c8aa0be3-ProtonGlow_Test_URS_1_page_7_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/776ef5f2-ProtonGlow_Test_URS_1_page_8.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/776ef5f2-ProtonGlow_Test_URS_1_page_8_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/042f030e-ProtonGlow_Test_URS_1_page_9.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/042f030e-ProtonGlow_Test_URS_1_page_9_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/5e5d7ccd-ProtonGlow_Test_URS_1_page_10.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/5e5d7ccd-ProtonGlow_Test_URS_1_page_10_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/58cd0367-ProtonGlow_Test_URS_1_page_11.png\n",
            "Skipping title inside table at coordinates: [275, 288, 2042, 501]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/58cd0367-ProtonGlow_Test_URS_1_page_11_reannotated.png\n",
            "Inserted 1 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/c9df1740-ProtonGlow_Test_URS_1_page_12.png\n",
            "Skipping title inside list at coordinates: [265, 272, 1940, 454]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/c9df1740-ProtonGlow_Test_URS_1_page_12_reannotated.png\n",
            "Inserted 1 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/a83b124d-ProtonGlow_Test_URS_1_page_13.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/a83b124d-ProtonGlow_Test_URS_1_page_13_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/dba943c5-ProtonGlow_Test_URS_1_page_14.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/dba943c5-ProtonGlow_Test_URS_1_page_14_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/68b58f6d-ProtonGlow_Test_URS_1_page_15.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/68b58f6d-ProtonGlow_Test_URS_1_page_15_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/f7c3a644-ProtonGlow_Test_URS_1_page_16.png\n",
            "Skipping title inside list at coordinates: [242, 2891, 2020, 2950]\n",
            "Skipping title inside list at coordinates: [287, 2973, 1053, 3060]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/f7c3a644-ProtonGlow_Test_URS_1_page_16_reannotated.png\n",
            "Inserted 2 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/f75fe9c4-ProtonGlow_Test_URS_1_page_17.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/f75fe9c4-ProtonGlow_Test_URS_1_page_17_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/9751783c-ProtonGlow_Test_URS_1_page_18.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/9751783c-ProtonGlow_Test_URS_1_page_18_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/3f57eebd-ProtonGlow_Test_URS_1_page_19.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/3f57eebd-ProtonGlow_Test_URS_1_page_19_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/7347d622-ProtonGlow_Test_URS_1_page_20.png\n",
            "Skipping title inside list at coordinates: [282, 247, 2180, 722]\n",
            "Skipping title inside list at coordinates: [278, 715, 1079, 799]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/7347d622-ProtonGlow_Test_URS_1_page_20_reannotated.png\n",
            "Inserted 2 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/043f5478-ProtonGlow_Test_URS_1_page_21.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/043f5478-ProtonGlow_Test_URS_1_page_21_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/ee1322e1-ProtonGlow_Test_URS_1_page_22.png\n",
            "Skipping title inside list at coordinates: [296, 3142, 2208, 3214]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/ee1322e1-ProtonGlow_Test_URS_1_page_22_reannotated.png\n",
            "Inserted 1 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/aa67a5ad-ProtonGlow_Test_URS_1_page_23.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/aa67a5ad-ProtonGlow_Test_URS_1_page_23_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/b20e4d9c-ProtonGlow_Test_URS_1_page_24.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/b20e4d9c-ProtonGlow_Test_URS_1_page_24_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/7226722b-ProtonGlow_Test_URS_1_page_25.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/7226722b-ProtonGlow_Test_URS_1_page_25_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/c77134ed-ProtonGlow_Test_URS_1_page_26.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/c77134ed-ProtonGlow_Test_URS_1_page_26_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/046cbd69-ProtonGlow_Test_URS_1_page_27.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/046cbd69-ProtonGlow_Test_URS_1_page_27_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/245272e6-ProtonGlow_Test_URS_1_page_28.png\n",
            "Skipping title inside list at coordinates: [481, 3149, 2165, 3210]\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/245272e6-ProtonGlow_Test_URS_1_page_28_reannotated.png\n",
            "Inserted 1 skipped blocks into skipped_block_items\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/eddd6c38-ProtonGlow_Test_URS_1_page_29.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/eddd6c38-ProtonGlow_Test_URS_1_page_29_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/f19c46f0-ProtonGlow_Test_URS_1_page_30.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/f19c46f0-ProtonGlow_Test_URS_1_page_30_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/48ed3ccf-ProtonGlow_Test_URS_1_page_31.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/48ed3ccf-ProtonGlow_Test_URS_1_page_31_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/fe7aa29b-ProtonGlow_Test_URS_1_page_32.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/fe7aa29b-ProtonGlow_Test_URS_1_page_32_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/d39b2cf1-ProtonGlow_Test_URS_1_page_33.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/d39b2cf1-ProtonGlow_Test_URS_1_page_33_reannotated.png\n",
            "Reannotating /content/drive/My Drive/lifesciences/post_label/images/32b16166-ProtonGlow_Test_URS_1_page_34.png\n",
            "Saved reannotated image: /content/drive/My Drive/lifesciences/retrained_staging/annotated/32b16166-ProtonGlow_Test_URS_1_page_34_reannotated.png\n",
            "Inserted/Updated 131 records into Neon PostgreSQL\n",
            "Updated batch run 16 status to SUCCESS\n",
            "Database connection closed\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import layoutparser as lp\n",
        "import detectron2\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.model_zoo import model_zoo\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from docx import Document\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import psycopg2\n",
        "from psycopg2.extras import execute_values\n",
        "from google.colab import drive\n",
        "\n",
        "# Configuration flag\n",
        "USE_POSTGRES = True\n",
        "\n",
        "# Neon PostgreSQL connection details\n",
        "DB_CONFIG = {\n",
        "    \"dbname\": \"neondb\",\n",
        "    \"user\": \"neondb_owner\",\n",
        "    \"password\": \"npg_DU3Vxoi6cCIu\",\n",
        "    \"host\": \"ep-purple-sound-a4z952yb-pooler.us-east-1.aws.neon.tech\",\n",
        "    \"port\": \"5432\",\n",
        "    \"sslmode\": \"require\"\n",
        "}\n",
        "\n",
        "# Device selection\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up directories\n",
        "BASE_DIR = \"/content/drive/My Drive/lifesciences\"\n",
        "SOURCE_DIR = Path(BASE_DIR) / \"training_documents\"\n",
        "PDF_STAGING_DIR = Path(BASE_DIR) / \"staging/pdf\"\n",
        "IMG_STAGING_DIR = Path(BASE_DIR) / \"post_label/images\"\n",
        "ANNOTATED_DIR = Path(BASE_DIR) / \"staging/annotated\"\n",
        "MODELS_DIR = Path(BASE_DIR) / \"models\"\n",
        "RETRAINED_STAGING_DIR = Path(BASE_DIR) / \"retrained_staging\"\n",
        "RETRAINED_ANNOTATED_DIR = RETRAINED_STAGING_DIR / \"annotated\"\n",
        "FAISS_INDEX_PATH = RETRAINED_STAGING_DIR / \"faiss_index.index\"\n",
        "RETRAINED_MODELS_DIR = RETRAINED_STAGING_DIR / \"models\"\n",
        "COCO_JSON_PATH = Path(BASE_DIR) / \"post_label/result.json\"\n",
        "\n",
        "# Create directories\n",
        "for directory in [SOURCE_DIR, PDF_STAGING_DIR, IMG_STAGING_DIR, ANNOTATED_DIR, MODELS_DIR, RETRAINED_STAGING_DIR, RETRAINED_ANNOTATED_DIR]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = 100000000\n",
        "\n",
        "# Global variables\n",
        "id_seq = 1\n",
        "sentence_model = None\n",
        "faiss_index = None\n",
        "model = None\n",
        "ocr_agent = None\n",
        "db_conn = None\n",
        "db_cursor = None\n",
        "run_number = 1\n",
        "run_date_time = datetime.now().isoformat()\n",
        "logged_in_user = \"admin\"\n",
        "\n",
        "COLORS = {\n",
        "    \"title\": (255, 0, 0), \"text\": (0, 255, 0), \"list\": (0, 0, 255),\n",
        "    \"table\": (255, 255, 0), \"figure\": (255, 0, 255)\n",
        "}\n",
        "\n",
        "LABEL_MAP = {0: \"figure\", 1: \"list\", 2: \"table\", 3: \"text\", 4: \"title\"}\n",
        "\n",
        "def map_and_update_coco_paths(json_path, image_dir):\n",
        "    try:\n",
        "        with open(json_path, \"r\") as f:\n",
        "            coco_data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON {json_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "    actual_images = {f: f for f in os.listdir(image_dir) if f.endswith(\".png\")}\n",
        "    print(f\"Actual images in {image_dir}: {list(actual_images.keys())}\")\n",
        "\n",
        "    updated_images = []\n",
        "    for image in coco_data[\"images\"]:\n",
        "        original_name = image[\"file_name\"]\n",
        "        cleaned_name = os.path.basename(original_name.replace(\"./images/\", \"\"))\n",
        "        if cleaned_name in actual_images:\n",
        "            image[\"file_name\"] = os.path.join(image_dir, cleaned_name)\n",
        "            updated_images.append(image)\n",
        "            print(f\"Mapped {original_name} to {image['file_name']}\")\n",
        "        else:\n",
        "            print(f\"No match found for {cleaned_name} in {image_dir}\")\n",
        "\n",
        "    coco_data[\"images\"] = updated_images\n",
        "    updated_json_path = RETRAINED_STAGING_DIR / \"results_mapped.json\"\n",
        "    with open(updated_json_path, \"w\") as f:\n",
        "        json.dump(coco_data, f, indent=2)\n",
        "    print(f\"Updated COCO JSON saved to {updated_json_path}\")\n",
        "    return updated_json_path\n",
        "\n",
        "def register_coco_dataset(json_path, image_dir):\n",
        "    dataset_name = \"custom_layout_dataset\"\n",
        "    try:\n",
        "        if dataset_name in DatasetCatalog:\n",
        "            DatasetCatalog.remove(dataset_name)\n",
        "            if dataset_name in MetadataCatalog:\n",
        "                MetadataCatalog.remove(dataset_name)\n",
        "            print(f\"Unregistered existing dataset: {dataset_name}\")\n",
        "\n",
        "        register_coco_instances(dataset_name, {}, str(json_path), image_dir)\n",
        "        MetadataCatalog.get(dataset_name).thing_classes = list(LABEL_MAP.values())\n",
        "        print(f\"Registered dataset: {dataset_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error registering dataset: {e}\")\n",
        "        raise\n",
        "    return dataset_name\n",
        "\n",
        "def train_layoutparser_model(json_path, image_dir):\n",
        "    global model\n",
        "    dataset_name = register_coco_dataset(json_path, image_dir)\n",
        "    cfg = get_cfg()\n",
        "\n",
        "    pretrained_model_path = os.path.join(MODELS_DIR, \"model_final.pth\")\n",
        "    if os.path.exists(pretrained_model_path):\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "        cfg.MODEL.WEIGHTS = pretrained_model_path\n",
        "        print(f\"Loaded pre-trained weights from {pretrained_model_path} (Faster R-CNN)\")\n",
        "    else:\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "        print(\"Using default Detectron2 Faster R-CNN model zoo weights\")\n",
        "\n",
        "    cfg.MODEL.DEVICE = str(device)  # \"cuda\" on T4 GPU\n",
        "    cfg.DATASETS.TRAIN = (dataset_name,)\n",
        "    cfg.DATASETS.TEST = ()\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 2  # GPU-friendly batch size\n",
        "    cfg.SOLVER.BASE_LR = 0.00025\n",
        "    cfg.SOLVER.MAX_ITER = 300\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(LABEL_MAP)\n",
        "    cfg.OUTPUT_DIR = str(RETRAINED_MODELS_DIR)\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=False)\n",
        "    trainer.train()\n",
        "\n",
        "    # Define model_path at function scope\n",
        "    model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "    config_path = os.path.join(cfg.OUTPUT_DIR, \"config.yaml\")\n",
        "    with open(config_path, \"w\") as f:\n",
        "        f.write(cfg.dump())\n",
        "\n",
        "    model = lp.Detectron2LayoutModel(\n",
        "        config_path=config_path,\n",
        "        model_path=model_path,\n",
        "        label_map=LABEL_MAP,\n",
        "        extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.2],\n",
        "        device=str(device)\n",
        "    )\n",
        "    print(f\"Model retrained and saved to {model_path}\")\n",
        "\n",
        "def lazy_load_models():\n",
        "    global model, ocr_agent\n",
        "    if ocr_agent is None:\n",
        "        try:\n",
        "            ocr_agent = lp.TesseractAgent(languages='eng', config='--psm 6 --oem 1')\n",
        "            print(\"OCR agent loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading OCR agent: {e}\")\n",
        "            raise\n",
        "    if model is None:\n",
        "        model_path = os.path.join(RETRAINED_MODELS_DIR, \"model_final.pth\")\n",
        "        config_path = os.path.join(RETRAINED_MODELS_DIR, \"config.yaml\")\n",
        "        if os.path.exists(model_path) and os.path.exists(config_path):\n",
        "            try:\n",
        "                model = lp.Detectron2LayoutModel(\n",
        "                    config_path=config_path,\n",
        "                    model_path=model_path,\n",
        "                    label_map=LABEL_MAP,\n",
        "                    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.2],\n",
        "                    device=str(device)\n",
        "                )\n",
        "                print(f\"Loaded retrained model from {model_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading model: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            print(f\"No retrained model or config found at {model_path} or {config_path}. Training required.\")\n",
        "\n",
        "def setup_db_connection():\n",
        "    global db_conn, db_cursor, run_number\n",
        "    if db_conn is None:\n",
        "        try:\n",
        "            db_conn = psycopg2.connect(**DB_CONFIG)\n",
        "            db_cursor = db_conn.cursor()\n",
        "            print(\"Connected to Neon PostgreSQL database\")\n",
        "            insert_batch_query = \"\"\"\n",
        "                INSERT INTO batch_run (run_date_time, run_by_user, run_final_status)\n",
        "                VALUES (%s, %s, 'RUNNING') RETURNING run_number\n",
        "            \"\"\"\n",
        "            db_cursor.execute(insert_batch_query, (run_date_time, logged_in_user))\n",
        "            run_number = db_cursor.fetchone()[0]\n",
        "            db_conn.commit()\n",
        "            print(f\"Started new batch run: {run_number}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to connect to Neon PostgreSQL: {e}\")\n",
        "            raise\n",
        "\n",
        "def update_run_status(status):\n",
        "    global db_conn, db_cursor, run_number\n",
        "    if db_conn is not None:\n",
        "        try:\n",
        "            update_query = \"\"\"\n",
        "                UPDATE batch_run\n",
        "                SET run_final_status = %s\n",
        "                WHERE run_number = %s\n",
        "            \"\"\"\n",
        "            db_cursor.execute(update_query, (status, run_number))\n",
        "            db_conn.commit()\n",
        "            print(f\"Updated batch run {run_number} status to {status}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to update run status: {e}\")\n",
        "            db_conn.rollback()\n",
        "\n",
        "def is_overlapping(rect1, rect2):\n",
        "    return not (rect1[2] <= rect2[0] or rect2[2] <= rect1[0] or\n",
        "                rect1[3] <= rect2[1] or rect2[3] <= rect1[1])\n",
        "\n",
        "def append_skipped_blocks_to_db(skipped_blocks):\n",
        "    if not skipped_blocks:\n",
        "        return\n",
        "\n",
        "    setup_db_connection()\n",
        "    try:\n",
        "        MAX_CONTENT_LENGTH = 1000\n",
        "        values = [\n",
        "            (\n",
        "                sb[\"run_number\"],\n",
        "                sb[\"parent_block_type\"],\n",
        "                sb[\"skipped_block_type\"],\n",
        "                sb[\"section_name\"][:255] if sb[\"section_name\"] else None,\n",
        "                sb[\"parent_block_content\"][:MAX_CONTENT_LENGTH-3] + \"...\" if len(sb[\"parent_block_content\"]) > MAX_CONTENT_LENGTH else sb[\"parent_block_content\"],\n",
        "                sb[\"skipped_block_content\"][:MAX_CONTENT_LENGTH-3] + \"...\" if len(sb[\"skipped_block_content\"]) > MAX_CONTENT_LENGTH else sb[\"skipped_block_content\"],\n",
        "                sb[\"parent_block_coordinates\"],\n",
        "                sb[\"skipped_block_coordinates\"]\n",
        "            )\n",
        "            for sb in skipped_blocks\n",
        "        ]\n",
        "        query = \"\"\"\n",
        "            INSERT INTO skipped_block_items (\n",
        "                run_number, parent_block_type, skipped_block_type, section_name,\n",
        "                parent_block_content, skipped_block_content,\n",
        "                parent_block_coordinates, skipped_block_coordinates\n",
        "            ) VALUES %s\n",
        "        \"\"\"\n",
        "        execute_values(db_cursor, query, values)\n",
        "        db_conn.commit()\n",
        "        print(f\"Inserted {len(skipped_blocks)} skipped blocks into skipped_block_items\")\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped blocks database error: {e}\")\n",
        "        db_conn.rollback()\n",
        "\n",
        "def process_layout(image_path, original_file_path):\n",
        "    global id_seq, model\n",
        "    lazy_load_models()\n",
        "\n",
        "    if model is None:\n",
        "        raise ValueError(\"Model not loaded. Ensure a trained model exists in RETRAINED_MODELS_DIR or run training.\")\n",
        "\n",
        "    try:\n",
        "        image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {image_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "    layout = model.detect(image)\n",
        "    sorted_layout = sorted(layout, key=lambda x: x.coordinates[1])\n",
        "    results = []\n",
        "    skipped_blocks = []\n",
        "    list_table_regions = [(b.type.lower(), list(map(int, b.coordinates)))\n",
        "                         for b in sorted_layout if b.type.lower() in [\"list\", \"table\"]]\n",
        "    current_section = \"No Title\"\n",
        "\n",
        "    list_table_contents = {}\n",
        "    for block_type, coords in list_table_regions:\n",
        "        cropped = image[coords[1]:coords[3], coords[0]:coords[2]]\n",
        "        content = ocr_agent.detect(cropped) or \"\"\n",
        "        if block_type == \"list\":\n",
        "            content = re.sub(r'[^a-zA-Z0-9\\s]', '', content)\n",
        "        elif block_type == \"table\":\n",
        "            content = '\\n'.join('-'.join(col.strip() for col in row.split() if col.strip())\n",
        "                               for row in content.split('\\n') if row.strip()) or \"Table Content\"\n",
        "        list_table_contents[tuple(coords)] = content.strip()\n",
        "        del cropped\n",
        "\n",
        "    block_number = 1\n",
        "    for block in sorted_layout:\n",
        "        coords = list(map(int, block.coordinates))\n",
        "        block_type = block.type.lower()\n",
        "\n",
        "        overlapping_region = next((r for r in list_table_regions if is_overlapping(coords, r[1])), None)\n",
        "        if block_type in [\"title\", \"text\"] and overlapping_region:\n",
        "            parent_type, parent_coords = overlapping_region\n",
        "            cropped = image[coords[1]:coords[3], coords[0]:coords[2]]\n",
        "            skipped_content = ocr_agent.detect(cropped) or \"\"\n",
        "            if block_type == \"title\":\n",
        "                skipped_content = skipped_content or \"Untitled\"\n",
        "            print(f\"Skipping {block_type} inside {parent_type} at coordinates: {coords}\")\n",
        "            skipped_blocks.append({\n",
        "                \"run_number\": run_number,\n",
        "                \"parent_block_type\": parent_type,\n",
        "                \"skipped_block_type\": block_type,\n",
        "                \"section_name\": current_section,\n",
        "                \"parent_block_content\": list_table_contents[tuple(parent_coords)],\n",
        "                \"skipped_block_content\": skipped_content.strip(),\n",
        "                \"parent_block_coordinates\": parent_coords,\n",
        "                \"skipped_block_coordinates\": coords\n",
        "            })\n",
        "            del cropped\n",
        "            continue\n",
        "\n",
        "        cropped = image[coords[1]:coords[3], coords[0]:coords[2]]\n",
        "        if block_type in [\"list\", \"table\"]:\n",
        "            content = list_table_contents[tuple(coords)]\n",
        "        elif block_type == \"title\":\n",
        "            content = ocr_agent.detect(cropped) or \"Untitled\"\n",
        "            current_section = content.lower()\n",
        "        else:\n",
        "            content = ocr_agent.detect(cropped) or \"\"\n",
        "\n",
        "        result = {\n",
        "            \"id\": id_seq,\n",
        "            \"urs\": Path(image_path).stem,\n",
        "            \"section\": current_section,\n",
        "            \"type\": block_type,\n",
        "            \"content\": content.strip(),\n",
        "            \"coordinates\": coords,\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"source_file\": str(original_file_path),\n",
        "            \"run_number\": run_number,\n",
        "            \"block_number\": block_number,\n",
        "        }\n",
        "        results.append(result)\n",
        "        id_seq += 1\n",
        "        block_number += 1\n",
        "\n",
        "        x1, y1, x2, y2 = coords\n",
        "        color = COLORS.get(block_type, (255, 255, 255))\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, f\"{block_type} #{block_number-1}\", (x1, y1-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "        del cropped\n",
        "\n",
        "    annotated_path = os.path.join(RETRAINED_ANNOTATED_DIR, f\"{Path(image_path).stem}_reannotated.png\")\n",
        "    success = cv2.imwrite(annotated_path, image, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "    if success:\n",
        "        print(f\"Saved reannotated image: {annotated_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to save reannotated image: {annotated_path}\")\n",
        "\n",
        "    del image\n",
        "    append_skipped_blocks_to_db(skipped_blocks)\n",
        "    return results\n",
        "\n",
        "def append_to_db(data):\n",
        "    if not data:\n",
        "        return\n",
        "\n",
        "    setup_db_connection()\n",
        "    try:\n",
        "        values = [\n",
        "            (d[\"id\"], d[\"urs\"], d[\"section\"], d[\"type\"], d[\"content\"],\n",
        "             d[\"coordinates\"][0], d[\"coordinates\"][1], d[\"coordinates\"][2], d[\"coordinates\"][3],\n",
        "             d[\"created_at\"], d[\"source_file\"], d[\"run_number\"], d[\"block_number\"])\n",
        "            for d in data\n",
        "        ]\n",
        "        query = \"\"\"\n",
        "            INSERT INTO document_metadata (\n",
        "                id, urs, section, type, content, coord_x1, coord_y1, coord_x2, coord_y2,\n",
        "                created_at, source_file, run_number, block_number\n",
        "            ) VALUES %s\n",
        "            ON CONFLICT (id) DO UPDATE SET\n",
        "                urs = EXCLUDED.urs,\n",
        "                section = EXCLUDED.section,\n",
        "                type = EXCLUDED.type,\n",
        "                content = EXCLUDED.content,\n",
        "                coord_x1 = EXCLUDED.coord_x1,\n",
        "                coord_y1 = EXCLUDED.coord_y1,\n",
        "                coord_x2 = EXCLUDED.coord_x2,\n",
        "                coord_y2 = EXCLUDED.coord_y2,\n",
        "                created_at = EXCLUDED.created_at,\n",
        "                source_file = EXCLUDED.source_file,\n",
        "                run_number = EXCLUDED.run_number,\n",
        "                block_number = EXCLUDED.block_number\n",
        "        \"\"\"\n",
        "        execute_values(db_cursor, query, values)\n",
        "        db_conn.commit()\n",
        "        print(f\"Inserted/Updated {len(data)} records into Neon PostgreSQL\")\n",
        "    except Exception as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "        db_conn.rollback()\n",
        "\n",
        "def process_and_reannotate(json_path):\n",
        "    try:\n",
        "        updated_json_path = map_and_update_coco_paths(json_path, IMG_STAGING_DIR)\n",
        "        train_layoutparser_model(updated_json_path, IMG_STAGING_DIR)\n",
        "\n",
        "        with open(updated_json_path, \"r\") as f:\n",
        "            coco_data = json.load(f)\n",
        "\n",
        "        results = []\n",
        "        for image_info in coco_data[\"images\"]:\n",
        "            image_path = image_info[\"file_name\"]\n",
        "            if os.path.exists(image_path):\n",
        "                print(f\"Reannotating {image_path}\")\n",
        "                results.extend(process_layout(image_path, image_path))\n",
        "            else:\n",
        "                print(f\"Image not found: {image_path}\")\n",
        "\n",
        "        append_to_db(results)\n",
        "        update_run_status('SUCCESS')\n",
        "    except Exception as e:\n",
        "        print(f\"Processing failed: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        update_run_status('FAILED')\n",
        "        raise\n",
        "\n",
        "def cleanup():\n",
        "    global db_conn, db_cursor\n",
        "    if db_conn is not None:\n",
        "        try:\n",
        "            db_cursor.execute(\"SELECT run_final_status FROM batch_run WHERE run_number = %s\", (run_number,))\n",
        "            current_status = db_cursor.fetchone()[0]\n",
        "            if current_status == 'RUNNING':\n",
        "                update_run_status('TERMINATED')\n",
        "        except Exception as e:\n",
        "            print(f\"Error during cleanup status check: {e}\")\n",
        "        finally:\n",
        "            db_cursor.close()\n",
        "            db_conn.close()\n",
        "            print(\"Database connection closed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            print(\"nvidia-smi failed:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"nvidia-smi not found or error: {e}\")\n",
        "\n",
        "    try:\n",
        "        process_and_reannotate(COCO_JSON_PATH)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Process interrupted by user\")\n",
        "        update_run_status('TERMINATED')\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        update_run_status('FAILED')\n",
        "    finally:\n",
        "        cleanup()"
      ]
    }
  ]
}